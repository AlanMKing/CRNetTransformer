{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51b3dc53-b619-439d-a6c7-54c9528f1dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import *\n",
    "from crnet_encoder_model import CRNETENCODER\n",
    "from crnet_encoder_dataset import CRNETENCODERDataset\n",
    "from crnet_encoder_loss import CRNETENCODERLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9afc3e1-385e-4886-a42a-da68b1d164fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_dir = r'/autodl-fs/data/Images/Train'\n",
    "gt_dirs = [ r'/autodl-fs/data/totaltext/Tf',\n",
    "            r'/autodl-fs/data/totaltext/Tc',\n",
    "            r'/autodl-fs/data/totaltext/Xoffset',\n",
    "            r'/autodl-fs/data/totaltext/Yoffset'\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71bdc144-2134-4bb4-980a-efdc502d2ddd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/autodl-fs/data/crnet2\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e496607c-7b93-49af-aa33-8d85a3f11041",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    # 超参数设置\n",
    "    num_epochs = 100\n",
    "    learning_rate = 0.0001\n",
    "    batch_size = 4\n",
    "    model_num = 8\n",
    "\n",
    "    # 加载数据集\n",
    "    dataset = CRNETENCODERDataset(image_dir, gt_dirs, target_size=(128, 128))  # target_size=(160, 160) 用于加载crnet的gt计算loss，目前未使用\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # 定义模型\n",
    "    if model_num == 0 :\n",
    "        model = CRNETENCODER().to(device)\n",
    "    else:\n",
    "        model = torch.load(f'/autodl-fs/data/crnet2/CE_model{model_num}.pth')\n",
    "\n",
    "    # 定义loss权重\n",
    "    weight_dict = {'loss_all': 2, 'loss_crnet': 0.5}\n",
    "    loss_fn = CRNETENCODERLoss()\n",
    "    loss_fn.to(device)\n",
    "\n",
    "    # 训练模型\n",
    "    for epoch in range(model_num, num_epochs):\n",
    "        if epoch > 10:\n",
    "            learning_rate *= 0.5\n",
    "            \n",
    "        # 定义优化器\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        model.train()\n",
    "\n",
    "        total_loss = 0\n",
    "        start_time = time.time()\n",
    "        print('***********************************************************************')\n",
    "        print(f'start training epoch{epoch + 1}')\n",
    "        for batch_idx, (images, gts) in enumerate(dataloader):\n",
    "            images = images.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 前向传播\n",
    "            outputs = model(images)\n",
    "\n",
    "            # 计算损失\n",
    "            loss_dict = loss_fn(outputs, gts)\n",
    "            losses = sum(loss_dict[k] * weight_dict[k] for k in loss_dict.keys() if k in weight_dict)\n",
    "            total_loss += losses.item()\n",
    "\n",
    "            # 反向传播和优化\n",
    "            losses.backward()\n",
    "            \n",
    "            # 检查梯度消失\n",
    "            num_layer = 0\n",
    "            if epoch >= 0:\n",
    "                for name, param in model.named_parameters():\n",
    "                    if param.grad is not None:\n",
    "                        if 'bias' in name:\n",
    "                            pass\n",
    "                        else:\n",
    "                            grad_norm = torch.norm(param.grad)\n",
    "                            # print(f'Layer: {name}, Gradient norm: {grad_norm.item()}')\n",
    "                            if grad_norm.item() < 1e-6:\n",
    "                                print(f'Step {batch_idx + 1} Warning: Gradient vanishing detected in layer {name}')\n",
    "                                num_layer += 1\n",
    "\n",
    "            # 梯度裁剪\n",
    "            # torch.nn.utils.clip_grad_norm_(detr.parameters(), max_norm=1.0)\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            end_time = time.time()\n",
    "            if (batch_idx + 1) % 50 == 0:\n",
    "                print(f'Loss_dict : {loss_dict}')\n",
    "                print(f\"Epoch [{epoch + 1}/{num_epochs}], Step [{batch_idx + 1}/{len(dataloader)}], Loss: {losses.item():.4f} , Use Time: {end_time - start_time}s\")\n",
    "\n",
    "        end_epoch_time = time.time()\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Average Loss: {total_loss / len(dataloader):.4f}, 1 Epoch Time {end_epoch_time - start_time} s\")\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            torch.save(model, f'CE_model{epoch+1}.pth')\n",
    "            print(f'Model {epoch+1} Already Saved')\n",
    "        print('***********************************************************************')\n",
    "\n",
    "    print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1399bae5-14f1-440a-a7a3-78cec9c8ec8f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************************************************************\n",
      "start training epoch9\n",
      "Loss_dict : {'loss_all': tensor(0.4799, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.4605, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [9/100], Step [50/314], Loss: 1.1900 , Use Time: 36.915157318115234s\n",
      "Loss_dict : {'loss_all': tensor(0.4072, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3878, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [9/100], Step [100/314], Loss: 1.0084 , Use Time: 75.78193616867065s\n",
      "Loss_dict : {'loss_all': tensor(0.9011, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.8873, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [9/100], Step [150/314], Loss: 2.2458 , Use Time: 111.70574760437012s\n",
      "Loss_dict : {'loss_all': tensor(0.5991, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.5134, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [9/100], Step [200/314], Loss: 1.4550 , Use Time: 146.92118525505066s\n",
      "Loss_dict : {'loss_all': tensor(0.5585, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.5116, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [9/100], Step [250/314], Loss: 1.3729 , Use Time: 183.15732192993164s\n",
      "Loss_dict : {'loss_all': tensor(0.4638, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.4172, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [9/100], Step [300/314], Loss: 1.1361 , Use Time: 219.39857864379883s\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.1.weight\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.2.weight\n",
      "Epoch [9/100], Average Loss: 1.5371, 1 Epoch Time 229.9271378517151 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch10\n",
      "Loss_dict : {'loss_all': tensor(0.6907, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.6417, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [10/100], Step [50/314], Loss: 1.7023 , Use Time: 39.68550729751587s\n",
      "Loss_dict : {'loss_all': tensor(0.5842, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.6245, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [10/100], Step [100/314], Loss: 1.4806 , Use Time: 82.54066872596741s\n",
      "Loss_dict : {'loss_all': tensor(0.6341, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.6739, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [10/100], Step [150/314], Loss: 1.6051 , Use Time: 121.07604336738586s\n",
      "Loss_dict : {'loss_all': tensor(0.6315, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.5715, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [10/100], Step [200/314], Loss: 1.5488 , Use Time: 158.39052891731262s\n",
      "Loss_dict : {'loss_all': tensor(1.1515, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(1.1509, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [10/100], Step [250/314], Loss: 2.8784 , Use Time: 196.53913831710815s\n",
      "Loss_dict : {'loss_all': tensor(0.3700, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3293, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [10/100], Step [300/314], Loss: 0.9047 , Use Time: 231.96620535850525s\n",
      "Epoch [10/100], Average Loss: 1.4725, 1 Epoch Time 241.87337160110474 s\n",
      "Model 10 Already Saved\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch11\n",
      "Loss_dict : {'loss_all': tensor(0.4292, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.4059, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [11/100], Step [50/314], Loss: 1.0614 , Use Time: 36.93731713294983s\n",
      "Loss_dict : {'loss_all': tensor(0.3242, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3076, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [11/100], Step [100/314], Loss: 0.8022 , Use Time: 73.0534725189209s\n",
      "Loss_dict : {'loss_all': tensor(0.3871, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3646, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [11/100], Step [150/314], Loss: 0.9564 , Use Time: 110.33884978294373s\n",
      "Loss_dict : {'loss_all': tensor(0.6329, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.6076, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [11/100], Step [200/314], Loss: 1.5696 , Use Time: 146.96873235702515s\n",
      "Loss_dict : {'loss_all': tensor(0.4194, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.4005, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [11/100], Step [250/314], Loss: 1.0391 , Use Time: 182.0683295726776s\n",
      "Loss_dict : {'loss_all': tensor(0.4710, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.4627, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [11/100], Step [300/314], Loss: 1.1733 , Use Time: 222.12114024162292s\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.1.weight\n",
      "Epoch [11/100], Average Loss: 1.3959, 1 Epoch Time 232.8037440776825 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch12\n",
      "Loss_dict : {'loss_all': tensor(0.3539, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3368, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [12/100], Step [50/314], Loss: 0.8762 , Use Time: 36.082242012023926s\n",
      "Loss_dict : {'loss_all': tensor(0.6134, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.6182, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [12/100], Step [100/314], Loss: 1.5359 , Use Time: 71.80232548713684s\n",
      "Loss_dict : {'loss_all': tensor(0.4287, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.4274, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [12/100], Step [150/314], Loss: 1.0712 , Use Time: 107.51883006095886s\n",
      "Loss_dict : {'loss_all': tensor(0.2652, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2518, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [12/100], Step [200/314], Loss: 0.6563 , Use Time: 144.07563400268555s\n",
      "Loss_dict : {'loss_all': tensor(0.6449, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.6175, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [12/100], Step [250/314], Loss: 1.5986 , Use Time: 181.09428334236145s\n",
      "Loss_dict : {'loss_all': tensor(0.4917, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.4505, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [12/100], Step [300/314], Loss: 1.2087 , Use Time: 216.92127895355225s\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.1.weight\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.2.weight\n",
      "Epoch [12/100], Average Loss: 1.2787, 1 Epoch Time 226.13489842414856 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch13\n",
      "Loss_dict : {'loss_all': tensor(0.3054, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2897, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [13/100], Step [50/314], Loss: 0.7557 , Use Time: 35.591228723526s\n",
      "Loss_dict : {'loss_all': tensor(0.3003, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2875, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [13/100], Step [100/314], Loss: 0.7444 , Use Time: 71.81556367874146s\n",
      "Loss_dict : {'loss_all': tensor(0.7068, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.6922, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [13/100], Step [150/314], Loss: 1.7596 , Use Time: 107.71686267852783s\n",
      "Loss_dict : {'loss_all': tensor(0.6352, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.6165, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [13/100], Step [200/314], Loss: 1.5786 , Use Time: 143.09812235832214s\n",
      "Loss_dict : {'loss_all': tensor(0.3942, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3735, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [13/100], Step [250/314], Loss: 0.9751 , Use Time: 178.1701695919037s\n",
      "Loss_dict : {'loss_all': tensor(0.5761, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.5711, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [13/100], Step [300/314], Loss: 1.4377 , Use Time: 215.3547022342682s\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.1.weight\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.2.weight\n",
      "Epoch [13/100], Average Loss: 1.1565, 1 Epoch Time 225.23472666740417 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch14\n",
      "Loss_dict : {'loss_all': tensor(0.2384, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2326, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [14/100], Step [50/314], Loss: 0.5930 , Use Time: 37.35307860374451s\n",
      "Loss_dict : {'loss_all': tensor(0.3157, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3280, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [14/100], Step [100/314], Loss: 0.7954 , Use Time: 74.19490718841553s\n",
      "Loss_dict : {'loss_all': tensor(0.2985, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3040, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [14/100], Step [150/314], Loss: 0.7490 , Use Time: 109.89368104934692s\n",
      "Loss_dict : {'loss_all': tensor(0.3180, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3255, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [14/100], Step [200/314], Loss: 0.7987 , Use Time: 145.29350352287292s\n",
      "Loss_dict : {'loss_all': tensor(0.8040, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.7923, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [14/100], Step [250/314], Loss: 2.0042 , Use Time: 180.91603469848633s\n",
      "Loss_dict : {'loss_all': tensor(0.3571, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3599, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [14/100], Step [300/314], Loss: 0.8941 , Use Time: 217.41897320747375s\n",
      "Epoch [14/100], Average Loss: 1.0939, 1 Epoch Time 226.8453652858734 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch15\n",
      "Loss_dict : {'loss_all': tensor(0.3106, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3291, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [15/100], Step [50/314], Loss: 0.7858 , Use Time: 35.97432827949524s\n",
      "Loss_dict : {'loss_all': tensor(0.3333, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3301, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [15/100], Step [100/314], Loss: 0.8317 , Use Time: 72.31546378135681s\n",
      "Loss_dict : {'loss_all': tensor(2.2515, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(2.2508, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [15/100], Step [150/314], Loss: 5.6284 , Use Time: 109.84563302993774s\n",
      "Loss_dict : {'loss_all': tensor(0.2407, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2629, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [15/100], Step [200/314], Loss: 0.6129 , Use Time: 145.38018012046814s\n",
      "Loss_dict : {'loss_all': tensor(0.2834, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2799, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [15/100], Step [250/314], Loss: 0.7068 , Use Time: 180.67814588546753s\n",
      "Loss_dict : {'loss_all': tensor(0.4127, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3852, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [15/100], Step [300/314], Loss: 1.0179 , Use Time: 216.49636030197144s\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.2.weight\n",
      "Epoch [15/100], Average Loss: 1.0546, 1 Epoch Time 226.29192686080933 s\n",
      "Model 15 Already Saved\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch16\n",
      "Loss_dict : {'loss_all': tensor(0.2744, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2581, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [16/100], Step [50/314], Loss: 0.6777 , Use Time: 35.39552044868469s\n",
      "Loss_dict : {'loss_all': tensor(0.7909, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.7921, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [16/100], Step [100/314], Loss: 1.9778 , Use Time: 71.34396481513977s\n",
      "Loss_dict : {'loss_all': tensor(1.1490, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(1.1441, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [16/100], Step [150/314], Loss: 2.8701 , Use Time: 106.9054307937622s\n",
      "Loss_dict : {'loss_all': tensor(0.2378, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2340, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [16/100], Step [200/314], Loss: 0.5926 , Use Time: 144.5465178489685s\n",
      "Loss_dict : {'loss_all': tensor(0.3231, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3356, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [16/100], Step [250/314], Loss: 0.8139 , Use Time: 181.72221326828003s\n",
      "Loss_dict : {'loss_all': tensor(0.3203, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3216, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [16/100], Step [300/314], Loss: 0.8013 , Use Time: 217.54042792320251s\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.1.weight\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.2.weight\n",
      "Epoch [16/100], Average Loss: 1.0517, 1 Epoch Time 227.27121591567993 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch17\n",
      "Loss_dict : {'loss_all': tensor(0.2221, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2335, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [17/100], Step [50/314], Loss: 0.5609 , Use Time: 36.3073308467865s\n",
      "Loss_dict : {'loss_all': tensor(0.2542, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2487, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [17/100], Step [100/314], Loss: 0.6327 , Use Time: 72.13556408882141s\n",
      "Loss_dict : {'loss_all': tensor(0.2577, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2795, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [17/100], Step [150/314], Loss: 0.6551 , Use Time: 108.34306693077087s\n",
      "Loss_dict : {'loss_all': tensor(0.2209, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2224, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [17/100], Step [200/314], Loss: 0.5530 , Use Time: 143.61664962768555s\n",
      "Loss_dict : {'loss_all': tensor(0.4321, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.4113, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [17/100], Step [250/314], Loss: 1.0699 , Use Time: 179.19880437850952s\n",
      "Loss_dict : {'loss_all': tensor(0.2707, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3152, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [17/100], Step [300/314], Loss: 0.6990 , Use Time: 215.95939135551453s\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.1.weight\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.2.weight\n",
      "Epoch [17/100], Average Loss: 1.0353, 1 Epoch Time 225.78750872612 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch18\n",
      "Loss_dict : {'loss_all': tensor(0.2480, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2586, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [18/100], Step [50/314], Loss: 0.6253 , Use Time: 36.16124081611633s\n",
      "Loss_dict : {'loss_all': tensor(0.6727, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.6680, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [18/100], Step [100/314], Loss: 1.6793 , Use Time: 73.0565755367279s\n",
      "Loss_dict : {'loss_all': tensor(0.7648, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.7571, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [18/100], Step [150/314], Loss: 1.9081 , Use Time: 108.79215288162231s\n",
      "Loss_dict : {'loss_all': tensor(0.2905, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2913, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [18/100], Step [200/314], Loss: 0.7266 , Use Time: 144.03660798072815s\n",
      "Loss_dict : {'loss_all': tensor(0.2436, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2508, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [18/100], Step [250/314], Loss: 0.6126 , Use Time: 179.70337080955505s\n",
      "Loss_dict : {'loss_all': tensor(0.2148, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2250, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [18/100], Step [300/314], Loss: 0.5421 , Use Time: 215.4284188747406s\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.2.weight\n",
      "Epoch [18/100], Average Loss: 1.0324, 1 Epoch Time 224.84509587287903 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch19\n",
      "Loss_dict : {'loss_all': tensor(0.3088, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2979, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [19/100], Step [50/314], Loss: 0.7666 , Use Time: 35.85899114608765s\n",
      "Loss_dict : {'loss_all': tensor(0.3780, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3866, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [19/100], Step [100/314], Loss: 0.9492 , Use Time: 72.50529265403748s\n",
      "Loss_dict : {'loss_all': tensor(0.2561, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2440, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [19/100], Step [150/314], Loss: 0.6341 , Use Time: 108.74144387245178s\n",
      "Loss_dict : {'loss_all': tensor(0.3526, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3468, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [19/100], Step [200/314], Loss: 0.8786 , Use Time: 143.740873336792s\n",
      "Loss_dict : {'loss_all': tensor(0.3439, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3447, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [19/100], Step [250/314], Loss: 0.8601 , Use Time: 179.81659173965454s\n",
      "Loss_dict : {'loss_all': tensor(0.2384, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2656, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [19/100], Step [300/314], Loss: 0.6096 , Use Time: 215.2019329071045s\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.1.weight\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.2.weight\n",
      "Epoch [19/100], Average Loss: 1.0296, 1 Epoch Time 224.74278235435486 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch20\n",
      "Loss_dict : {'loss_all': tensor(0.7832, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.7782, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [20/100], Step [50/314], Loss: 1.9555 , Use Time: 36.93238878250122s\n",
      "Loss_dict : {'loss_all': tensor(0.2377, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2325, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [20/100], Step [100/314], Loss: 0.5916 , Use Time: 72.86987257003784s\n",
      "Loss_dict : {'loss_all': tensor(0.3762, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3910, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [20/100], Step [150/314], Loss: 0.9479 , Use Time: 110.40577340126038s\n",
      "Loss_dict : {'loss_all': tensor(0.2213, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2202, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [20/100], Step [200/314], Loss: 0.5526 , Use Time: 149.35475087165833s\n",
      "Loss_dict : {'loss_all': tensor(0.9444, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.9564, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [20/100], Step [250/314], Loss: 2.3670 , Use Time: 189.26800322532654s\n",
      "Loss_dict : {'loss_all': tensor(0.2204, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2184, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [20/100], Step [300/314], Loss: 0.5499 , Use Time: 235.10309767723083s\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.1.weight\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.2.weight\n",
      "Epoch [20/100], Average Loss: 1.0253, 1 Epoch Time 246.97690892219543 s\n",
      "Model 20 Already Saved\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch21\n",
      "Loss_dict : {'loss_all': tensor(0.2191, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2234, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [21/100], Step [50/314], Loss: 0.5499 , Use Time: 42.652503490448s\n",
      "Loss_dict : {'loss_all': tensor(0.2590, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2732, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [21/100], Step [100/314], Loss: 0.6546 , Use Time: 80.83956980705261s\n",
      "Loss_dict : {'loss_all': tensor(0.2595, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2740, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [21/100], Step [150/314], Loss: 0.6560 , Use Time: 117.53471994400024s\n",
      "Loss_dict : {'loss_all': tensor(0.3127, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2906, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [21/100], Step [200/314], Loss: 0.7708 , Use Time: 153.98747515678406s\n",
      "Loss_dict : {'loss_all': tensor(0.2711, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2749, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [21/100], Step [250/314], Loss: 0.6796 , Use Time: 190.3957543373108s\n",
      "Loss_dict : {'loss_all': tensor(0.2844, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2788, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [21/100], Step [300/314], Loss: 0.7083 , Use Time: 229.07555651664734s\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.1.weight\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.2.weight\n",
      "Epoch [21/100], Average Loss: 1.0174, 1 Epoch Time 239.21569561958313 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch22\n",
      "Loss_dict : {'loss_all': tensor(0.3370, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3156, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [22/100], Step [50/314], Loss: 0.8318 , Use Time: 35.114027976989746s\n",
      "Loss_dict : {'loss_all': tensor(0.2349, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2325, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [22/100], Step [100/314], Loss: 0.5859 , Use Time: 71.11958074569702s\n",
      "Loss_dict : {'loss_all': tensor(0.2566, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2557, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [22/100], Step [150/314], Loss: 0.6410 , Use Time: 107.67012405395508s\n",
      "Loss_dict : {'loss_all': tensor(0.7653, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.7662, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [22/100], Step [200/314], Loss: 1.9136 , Use Time: 143.01599860191345s\n",
      "Loss_dict : {'loss_all': tensor(0.2237, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2237, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [22/100], Step [250/314], Loss: 0.5592 , Use Time: 178.26797771453857s\n",
      "Loss_dict : {'loss_all': tensor(0.2383, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2517, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [22/100], Step [300/314], Loss: 0.6024 , Use Time: 213.9154543876648s\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.2.weight\n",
      "Epoch [22/100], Average Loss: 1.0259, 1 Epoch Time 223.21507692337036 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch23\n",
      "Loss_dict : {'loss_all': tensor(0.6809, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.6873, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [23/100], Step [50/314], Loss: 1.7054 , Use Time: 36.261507749557495s\n",
      "Loss_dict : {'loss_all': tensor(0.2698, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2921, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [23/100], Step [100/314], Loss: 0.6857 , Use Time: 71.25279140472412s\n",
      "Loss_dict : {'loss_all': tensor(0.2579, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2581, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [23/100], Step [150/314], Loss: 0.6448 , Use Time: 106.86835741996765s\n",
      "Loss_dict : {'loss_all': tensor(0.2503, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2566, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [23/100], Step [200/314], Loss: 0.6290 , Use Time: 141.8636815547943s\n",
      "Loss_dict : {'loss_all': tensor(0.5368, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.5414, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [23/100], Step [250/314], Loss: 1.3442 , Use Time: 179.04923295974731s\n",
      "Loss_dict : {'loss_all': tensor(0.2827, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2768, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [23/100], Step [300/314], Loss: 0.7039 , Use Time: 214.3401141166687s\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.1.weight\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.2.weight\n",
      "Epoch [23/100], Average Loss: 1.0304, 1 Epoch Time 223.65371894836426 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch24\n",
      "Loss_dict : {'loss_all': tensor(0.2427, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2416, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [24/100], Step [50/314], Loss: 0.6061 , Use Time: 35.880038261413574s\n",
      "Loss_dict : {'loss_all': tensor(0.2076, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2075, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [24/100], Step [100/314], Loss: 0.5189 , Use Time: 72.82046866416931s\n",
      "Loss_dict : {'loss_all': tensor(0.3386, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3337, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [24/100], Step [150/314], Loss: 0.8441 , Use Time: 109.2375123500824s\n",
      "Loss_dict : {'loss_all': tensor(0.3460, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3491, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [24/100], Step [200/314], Loss: 0.8665 , Use Time: 146.1067910194397s\n",
      "Loss_dict : {'loss_all': tensor(0.3322, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3377, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [24/100], Step [250/314], Loss: 0.8333 , Use Time: 181.5935685634613s\n",
      "Loss_dict : {'loss_all': tensor(0.3339, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3288, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [24/100], Step [300/314], Loss: 0.8321 , Use Time: 217.50593090057373s\n",
      "Epoch [24/100], Average Loss: 1.0159, 1 Epoch Time 226.98360109329224 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch25\n",
      "Loss_dict : {'loss_all': tensor(0.2636, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2718, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [25/100], Step [50/314], Loss: 0.6631 , Use Time: 35.71057653427124s\n",
      "Loss_dict : {'loss_all': tensor(0.2663, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2704, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [25/100], Step [100/314], Loss: 0.6677 , Use Time: 71.27524876594543s\n",
      "Loss_dict : {'loss_all': tensor(0.2884, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2846, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [25/100], Step [150/314], Loss: 0.7192 , Use Time: 108.59150433540344s\n",
      "Loss_dict : {'loss_all': tensor(0.2594, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2597, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [25/100], Step [200/314], Loss: 0.6487 , Use Time: 146.86859250068665s\n",
      "Loss_dict : {'loss_all': tensor(0.6159, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.6201, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [25/100], Step [250/314], Loss: 1.5419 , Use Time: 184.19456148147583s\n",
      "Loss_dict : {'loss_all': tensor(0.3393, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3412, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [25/100], Step [300/314], Loss: 0.8492 , Use Time: 220.31942224502563s\n",
      "Epoch [25/100], Average Loss: 1.0284, 1 Epoch Time 230.01901412010193 s\n",
      "Model 25 Already Saved\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch26\n",
      "Loss_dict : {'loss_all': tensor(0.3118, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3149, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [26/100], Step [50/314], Loss: 0.7809 , Use Time: 35.38859701156616s\n",
      "Loss_dict : {'loss_all': tensor(0.4755, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.4763, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [26/100], Step [100/314], Loss: 1.1892 , Use Time: 71.0553092956543s\n",
      "Loss_dict : {'loss_all': tensor(0.2589, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2577, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [26/100], Step [150/314], Loss: 0.6467 , Use Time: 106.1472659111023s\n",
      "Loss_dict : {'loss_all': tensor(0.2509, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2717, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [26/100], Step [200/314], Loss: 0.6376 , Use Time: 141.2133014202118s\n",
      "Loss_dict : {'loss_all': tensor(0.2151, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.1956, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [26/100], Step [250/314], Loss: 0.5280 , Use Time: 177.24523210525513s\n",
      "Loss_dict : {'loss_all': tensor(0.2189, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2366, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [26/100], Step [300/314], Loss: 0.5561 , Use Time: 212.97978973388672s\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.1.weight\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.2.weight\n",
      "Epoch [26/100], Average Loss: 1.0177, 1 Epoch Time 222.57456398010254 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch27\n",
      "Loss_dict : {'loss_all': tensor(0.3001, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3050, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [27/100], Step [50/314], Loss: 0.7526 , Use Time: 36.530447244644165s\n",
      "Loss_dict : {'loss_all': tensor(0.6721, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.6905, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [27/100], Step [100/314], Loss: 1.6894 , Use Time: 72.88592147827148s\n",
      "Loss_dict : {'loss_all': tensor(0.2819, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2884, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [27/100], Step [150/314], Loss: 0.7081 , Use Time: 112.02856636047363s\n",
      "Loss_dict : {'loss_all': tensor(0.3359, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3206, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [27/100], Step [200/314], Loss: 0.8321 , Use Time: 147.1503143310547s\n",
      "Loss_dict : {'loss_all': tensor(0.4272, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.4386, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [27/100], Step [250/314], Loss: 1.0738 , Use Time: 182.7413146495819s\n",
      "Loss_dict : {'loss_all': tensor(0.2473, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2553, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [27/100], Step [300/314], Loss: 0.6222 , Use Time: 222.0134563446045s\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.1.weight\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.2.weight\n",
      "Epoch [27/100], Average Loss: 1.0250, 1 Epoch Time 232.49542450904846 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch28\n",
      "Loss_dict : {'loss_all': tensor(0.8194, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.8276, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [28/100], Step [50/314], Loss: 2.0526 , Use Time: 36.37317991256714s\n",
      "Loss_dict : {'loss_all': tensor(0.2639, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2653, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [28/100], Step [100/314], Loss: 0.6605 , Use Time: 74.94729852676392s\n",
      "Loss_dict : {'loss_all': tensor(0.2790, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2816, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [28/100], Step [150/314], Loss: 0.6989 , Use Time: 113.4984073638916s\n",
      "Loss_dict : {'loss_all': tensor(0.9959, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(1.0003, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [28/100], Step [200/314], Loss: 2.4919 , Use Time: 149.5027575492859s\n",
      "Loss_dict : {'loss_all': tensor(0.2042, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2033, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [28/100], Step [250/314], Loss: 0.5100 , Use Time: 188.74670839309692s\n",
      "Loss_dict : {'loss_all': tensor(0.2107, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.1960, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [28/100], Step [300/314], Loss: 0.5194 , Use Time: 226.96666741371155s\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.1.weight\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.2.weight\n",
      "Epoch [28/100], Average Loss: 1.0449, 1 Epoch Time 237.4025685787201 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch29\n",
      "Loss_dict : {'loss_all': tensor(0.1825, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.1940, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [29/100], Step [50/314], Loss: 0.4620 , Use Time: 35.51831388473511s\n",
      "Loss_dict : {'loss_all': tensor(0.3583, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3742, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [29/100], Step [100/314], Loss: 0.9038 , Use Time: 71.67167067527771s\n",
      "Loss_dict : {'loss_all': tensor(0.5511, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.5641, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [29/100], Step [150/314], Loss: 1.3842 , Use Time: 107.93975782394409s\n",
      "Loss_dict : {'loss_all': tensor(0.1923, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2086, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [29/100], Step [200/314], Loss: 0.4889 , Use Time: 144.08393025398254s\n",
      "Loss_dict : {'loss_all': tensor(0.2783, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2802, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [29/100], Step [250/314], Loss: 0.6968 , Use Time: 182.66057777404785s\n",
      "Loss_dict : {'loss_all': tensor(0.1847, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.1931, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [29/100], Step [300/314], Loss: 0.4659 , Use Time: 218.4592628479004s\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.0.weight\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.1.weight\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.2.weight\n",
      "Epoch [29/100], Average Loss: 1.0233, 1 Epoch Time 228.09029984474182 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch30\n",
      "Loss_dict : {'loss_all': tensor(0.2964, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3122, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [30/100], Step [50/314], Loss: 0.7489 , Use Time: 36.17017078399658s\n",
      "Loss_dict : {'loss_all': tensor(0.2490, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2345, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [30/100], Step [100/314], Loss: 0.6152 , Use Time: 71.50502586364746s\n",
      "Loss_dict : {'loss_all': tensor(0.3063, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3166, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [30/100], Step [150/314], Loss: 0.7709 , Use Time: 106.46050381660461s\n",
      "Loss_dict : {'loss_all': tensor(0.3816, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3733, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [30/100], Step [200/314], Loss: 0.9498 , Use Time: 142.15480637550354s\n",
      "Loss_dict : {'loss_all': tensor(0.3364, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3432, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [30/100], Step [250/314], Loss: 0.8443 , Use Time: 178.13157868385315s\n",
      "Loss_dict : {'loss_all': tensor(0.9044, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.9116, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [30/100], Step [300/314], Loss: 2.2646 , Use Time: 213.91372179985046s\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.1.weight\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.2.weight\n",
      "Epoch [30/100], Average Loss: 1.0282, 1 Epoch Time 223.7197139263153 s\n",
      "Model 30 Already Saved\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch31\n",
      "Loss_dict : {'loss_all': tensor(0.2042, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2251, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [31/100], Step [50/314], Loss: 0.5209 , Use Time: 36.947171688079834s\n",
      "Loss_dict : {'loss_all': tensor(0.3145, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3136, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [31/100], Step [100/314], Loss: 0.7858 , Use Time: 73.40170073509216s\n",
      "Loss_dict : {'loss_all': tensor(0.2219, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2436, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [31/100], Step [150/314], Loss: 0.5657 , Use Time: 109.24834442138672s\n",
      "Loss_dict : {'loss_all': tensor(0.2148, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2083, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [31/100], Step [200/314], Loss: 0.5338 , Use Time: 145.84189701080322s\n",
      "Loss_dict : {'loss_all': tensor(0.4722, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.4676, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [31/100], Step [250/314], Loss: 1.1782 , Use Time: 182.58515882492065s\n",
      "Loss_dict : {'loss_all': tensor(0.2211, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2347, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [31/100], Step [300/314], Loss: 0.5596 , Use Time: 218.47820210456848s\n",
      "Epoch [31/100], Average Loss: 1.0166, 1 Epoch Time 227.95279836654663 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch32\n",
      "Loss_dict : {'loss_all': tensor(0.3964, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3736, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [32/100], Step [50/314], Loss: 0.9797 , Use Time: 34.993584394454956s\n",
      "Loss_dict : {'loss_all': tensor(0.2540, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2750, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [32/100], Step [100/314], Loss: 0.6455 , Use Time: 72.18486833572388s\n",
      "Loss_dict : {'loss_all': tensor(0.1538, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.1812, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [32/100], Step [150/314], Loss: 0.3981 , Use Time: 108.92717480659485s\n",
      "Loss_dict : {'loss_all': tensor(0.3725, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3511, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [32/100], Step [200/314], Loss: 0.9206 , Use Time: 144.30431270599365s\n",
      "Loss_dict : {'loss_all': tensor(0.3743, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3873, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [32/100], Step [250/314], Loss: 0.9422 , Use Time: 179.5649495124817s\n",
      "Loss_dict : {'loss_all': tensor(1.3435, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(1.3279, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [32/100], Step [300/314], Loss: 3.3510 , Use Time: 215.1037871837616s\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.2.weight\n",
      "Epoch [32/100], Average Loss: 1.0142, 1 Epoch Time 224.71077299118042 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch33\n",
      "Loss_dict : {'loss_all': tensor(0.2772, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2800, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [33/100], Step [50/314], Loss: 0.6945 , Use Time: 35.36448526382446s\n",
      "Loss_dict : {'loss_all': tensor(0.8829, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.8816, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [33/100], Step [100/314], Loss: 2.2065 , Use Time: 70.99770498275757s\n",
      "Loss_dict : {'loss_all': tensor(0.2502, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2425, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [33/100], Step [150/314], Loss: 0.6216 , Use Time: 105.92396211624146s\n",
      "Loss_dict : {'loss_all': tensor(0.2908, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2999, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [33/100], Step [200/314], Loss: 0.7315 , Use Time: 144.16806888580322s\n",
      "Loss_dict : {'loss_all': tensor(0.2752, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2761, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [33/100], Step [250/314], Loss: 0.6885 , Use Time: 180.88856029510498s\n",
      "Loss_dict : {'loss_all': tensor(0.5581, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.5656, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [33/100], Step [300/314], Loss: 1.3991 , Use Time: 216.98599910736084s\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.1.weight\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.2.weight\n",
      "Epoch [33/100], Average Loss: 1.0238, 1 Epoch Time 226.45836520195007 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch34\n",
      "Loss_dict : {'loss_all': tensor(0.2468, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2616, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [34/100], Step [50/314], Loss: 0.6243 , Use Time: 36.163461208343506s\n",
      "Loss_dict : {'loss_all': tensor(0.1998, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.1928, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [34/100], Step [100/314], Loss: 0.4961 , Use Time: 72.60256719589233s\n",
      "Loss_dict : {'loss_all': tensor(0.3939, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3893, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [34/100], Step [150/314], Loss: 0.9825 , Use Time: 108.77975869178772s\n",
      "Loss_dict : {'loss_all': tensor(1.0462, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(1.0585, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [34/100], Step [200/314], Loss: 2.6216 , Use Time: 148.00223803520203s\n",
      "Loss_dict : {'loss_all': tensor(0.4315, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.4279, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [34/100], Step [250/314], Loss: 1.0770 , Use Time: 187.87753295898438s\n",
      "Loss_dict : {'loss_all': tensor(0.9381, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.9417, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [34/100], Step [300/314], Loss: 2.3470 , Use Time: 228.653151512146s\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.1.weight\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.2.weight\n",
      "Epoch [34/100], Average Loss: 1.0261, 1 Epoch Time 238.77379083633423 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch35\n",
      "Loss_dict : {'loss_all': tensor(0.3098, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3203, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [35/100], Step [50/314], Loss: 0.7798 , Use Time: 39.77202248573303s\n",
      "Loss_dict : {'loss_all': tensor(2.2926, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(2.3068, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [35/100], Step [100/314], Loss: 5.7387 , Use Time: 75.35516929626465s\n",
      "Loss_dict : {'loss_all': tensor(0.1906, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.1970, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [35/100], Step [150/314], Loss: 0.4798 , Use Time: 111.27847361564636s\n",
      "Loss_dict : {'loss_all': tensor(0.2262, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2450, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [35/100], Step [200/314], Loss: 0.5750 , Use Time: 147.19917178153992s\n",
      "Loss_dict : {'loss_all': tensor(0.2797, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2638, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [35/100], Step [250/314], Loss: 0.6912 , Use Time: 183.98703622817993s\n",
      "Loss_dict : {'loss_all': tensor(0.3451, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3547, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [35/100], Step [300/314], Loss: 0.8676 , Use Time: 220.73237299919128s\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.2.weight\n",
      "Epoch [35/100], Average Loss: 1.0257, 1 Epoch Time 230.09622979164124 s\n",
      "Model 35 Already Saved\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch36\n",
      "Loss_dict : {'loss_all': tensor(0.3125, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3100, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [36/100], Step [50/314], Loss: 0.7799 , Use Time: 36.42630219459534s\n",
      "Loss_dict : {'loss_all': tensor(0.7149, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.7305, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [36/100], Step [100/314], Loss: 1.7950 , Use Time: 72.55737113952637s\n",
      "Loss_dict : {'loss_all': tensor(0.2116, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.1994, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [36/100], Step [150/314], Loss: 0.5228 , Use Time: 109.64553046226501s\n",
      "Loss_dict : {'loss_all': tensor(0.2361, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2416, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [36/100], Step [200/314], Loss: 0.5929 , Use Time: 146.3729157447815s\n",
      "Loss_dict : {'loss_all': tensor(0.2344, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2324, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [36/100], Step [250/314], Loss: 0.5850 , Use Time: 182.44670486450195s\n",
      "Loss_dict : {'loss_all': tensor(0.2627, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2812, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [36/100], Step [300/314], Loss: 0.6660 , Use Time: 217.26665234565735s\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.2.weight\n",
      "Epoch [36/100], Average Loss: 1.0090, 1 Epoch Time 227.30585837364197 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch37\n",
      "Loss_dict : {'loss_all': tensor(0.3673, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3766, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [37/100], Step [50/314], Loss: 0.9229 , Use Time: 35.62784767150879s\n",
      "Loss_dict : {'loss_all': tensor(0.8280, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.8410, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [37/100], Step [100/314], Loss: 2.0765 , Use Time: 72.20484232902527s\n",
      "Loss_dict : {'loss_all': tensor(0.2785, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2868, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [37/100], Step [150/314], Loss: 0.7003 , Use Time: 113.08174252510071s\n",
      "Loss_dict : {'loss_all': tensor(1.7914, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(1.7959, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [37/100], Step [200/314], Loss: 4.4808 , Use Time: 154.315447807312s\n",
      "Loss_dict : {'loss_all': tensor(0.3283, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3420, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [37/100], Step [250/314], Loss: 0.8276 , Use Time: 194.03568840026855s\n",
      "Loss_dict : {'loss_all': tensor(0.2312, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2250, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [37/100], Step [300/314], Loss: 0.5748 , Use Time: 231.32301831245422s\n",
      "Epoch [37/100], Average Loss: 1.0486, 1 Epoch Time 240.5758752822876 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch38\n",
      "Loss_dict : {'loss_all': tensor(0.2800, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2843, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [38/100], Step [50/314], Loss: 0.7021 , Use Time: 36.05728840827942s\n",
      "Loss_dict : {'loss_all': tensor(0.4014, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3784, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [38/100], Step [100/314], Loss: 0.9920 , Use Time: 70.85912990570068s\n",
      "Loss_dict : {'loss_all': tensor(0.2476, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2403, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [38/100], Step [150/314], Loss: 0.6153 , Use Time: 107.15855073928833s\n",
      "Loss_dict : {'loss_all': tensor(0.4753, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.4728, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [38/100], Step [200/314], Loss: 1.1871 , Use Time: 143.3386538028717s\n",
      "Loss_dict : {'loss_all': tensor(0.2496, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2517, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [38/100], Step [250/314], Loss: 0.6250 , Use Time: 182.34995865821838s\n",
      "Loss_dict : {'loss_all': tensor(2.3164, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(2.3193, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [38/100], Step [300/314], Loss: 5.7925 , Use Time: 220.89125299453735s\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.1.weight\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.2.weight\n",
      "Epoch [38/100], Average Loss: 1.0225, 1 Epoch Time 230.53059673309326 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch39\n",
      "Loss_dict : {'loss_all': tensor(1.2048, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(1.1980, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [39/100], Step [50/314], Loss: 3.0086 , Use Time: 37.308773040771484s\n",
      "Loss_dict : {'loss_all': tensor(0.2452, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2623, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [39/100], Step [100/314], Loss: 0.6215 , Use Time: 72.34171628952026s\n",
      "Loss_dict : {'loss_all': tensor(0.4297, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.4256, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [39/100], Step [150/314], Loss: 1.0722 , Use Time: 108.7491865158081s\n",
      "Loss_dict : {'loss_all': tensor(0.2952, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2742, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [39/100], Step [200/314], Loss: 0.7274 , Use Time: 146.93074941635132s\n",
      "Loss_dict : {'loss_all': tensor(0.3905, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3769, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [39/100], Step [250/314], Loss: 0.9695 , Use Time: 184.94460344314575s\n",
      "Loss_dict : {'loss_all': tensor(0.2795, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2554, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [39/100], Step [300/314], Loss: 0.6867 , Use Time: 222.45927906036377s\n",
      "Epoch [39/100], Average Loss: 1.0222, 1 Epoch Time 232.55795788764954 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch40\n",
      "Loss_dict : {'loss_all': tensor(0.3759, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3413, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [40/100], Step [50/314], Loss: 0.9224 , Use Time: 39.530213356018066s\n",
      "Loss_dict : {'loss_all': tensor(0.2398, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2630, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [40/100], Step [100/314], Loss: 0.6112 , Use Time: 76.56327557563782s\n",
      "Loss_dict : {'loss_all': tensor(0.3982, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3938, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [40/100], Step [150/314], Loss: 0.9934 , Use Time: 112.77541637420654s\n",
      "Loss_dict : {'loss_all': tensor(0.4885, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.4939, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [40/100], Step [200/314], Loss: 1.2239 , Use Time: 148.88704705238342s\n",
      "Loss_dict : {'loss_all': tensor(0.5216, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.5207, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [40/100], Step [250/314], Loss: 1.3035 , Use Time: 187.75697684288025s\n",
      "Loss_dict : {'loss_all': tensor(0.2184, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2382, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [40/100], Step [300/314], Loss: 0.5559 , Use Time: 225.78851008415222s\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.1.weight\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.2.weight\n",
      "Epoch [40/100], Average Loss: 1.0219, 1 Epoch Time 235.1279101371765 s\n",
      "Model 40 Already Saved\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch41\n",
      "Loss_dict : {'loss_all': tensor(0.2341, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2397, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [41/100], Step [50/314], Loss: 0.5881 , Use Time: 37.148359298706055s\n",
      "Loss_dict : {'loss_all': tensor(0.2618, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2532, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [41/100], Step [100/314], Loss: 0.6501 , Use Time: 73.21591234207153s\n",
      "Loss_dict : {'loss_all': tensor(0.2444, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2543, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [41/100], Step [150/314], Loss: 0.6160 , Use Time: 110.70012402534485s\n",
      "Loss_dict : {'loss_all': tensor(0.1919, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.1967, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [41/100], Step [200/314], Loss: 0.4822 , Use Time: 147.91874408721924s\n",
      "Loss_dict : {'loss_all': tensor(0.2648, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2506, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [41/100], Step [250/314], Loss: 0.6549 , Use Time: 183.3644049167633s\n",
      "Loss_dict : {'loss_all': tensor(0.3304, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3339, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [41/100], Step [300/314], Loss: 0.8278 , Use Time: 219.2364640235901s\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.1.weight\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.2.weight\n",
      "Epoch [41/100], Average Loss: 1.0248, 1 Epoch Time 229.09476590156555 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch42\n",
      "Loss_dict : {'loss_all': tensor(0.2767, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2970, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [42/100], Step [50/314], Loss: 0.7020 , Use Time: 37.66056776046753s\n",
      "Loss_dict : {'loss_all': tensor(0.5407, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.5388, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [42/100], Step [100/314], Loss: 1.3507 , Use Time: 77.4755597114563s\n",
      "Loss_dict : {'loss_all': tensor(0.3032, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3088, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [42/100], Step [150/314], Loss: 0.7609 , Use Time: 113.45078206062317s\n",
      "Loss_dict : {'loss_all': tensor(0.3225, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2919, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [42/100], Step [200/314], Loss: 0.7910 , Use Time: 150.32039093971252s\n",
      "Loss_dict : {'loss_all': tensor(0.2386, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2457, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [42/100], Step [250/314], Loss: 0.6000 , Use Time: 188.79873418807983s\n",
      "Loss_dict : {'loss_all': tensor(0.4581, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.4457, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [42/100], Step [300/314], Loss: 1.1390 , Use Time: 225.40900230407715s\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.0.weight\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.1.weight\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.2.weight\n",
      "Epoch [42/100], Average Loss: 1.0291, 1 Epoch Time 234.8081407546997 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch43\n",
      "Loss_dict : {'loss_all': tensor(0.3769, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3606, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [43/100], Step [50/314], Loss: 0.9342 , Use Time: 35.67065644264221s\n",
      "Loss_dict : {'loss_all': tensor(0.2661, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2619, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [43/100], Step [100/314], Loss: 0.6632 , Use Time: 71.52779722213745s\n",
      "Loss_dict : {'loss_all': tensor(0.1868, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2053, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [43/100], Step [150/314], Loss: 0.4763 , Use Time: 107.14129829406738s\n",
      "Loss_dict : {'loss_all': tensor(0.2535, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2367, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [43/100], Step [200/314], Loss: 0.6253 , Use Time: 143.56386017799377s\n",
      "Loss_dict : {'loss_all': tensor(0.2835, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2871, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [43/100], Step [250/314], Loss: 0.7106 , Use Time: 179.2784149646759s\n",
      "Loss_dict : {'loss_all': tensor(0.2184, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2284, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [43/100], Step [300/314], Loss: 0.5510 , Use Time: 216.13464498519897s\n",
      "Epoch [43/100], Average Loss: 1.0321, 1 Epoch Time 226.60534524917603 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch44\n",
      "Loss_dict : {'loss_all': tensor(0.2130, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2204, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [44/100], Step [50/314], Loss: 0.5362 , Use Time: 35.94223666191101s\n",
      "Loss_dict : {'loss_all': tensor(0.2589, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2812, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [44/100], Step [100/314], Loss: 0.6584 , Use Time: 71.80181884765625s\n",
      "Loss_dict : {'loss_all': tensor(0.7944, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.8006, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [44/100], Step [150/314], Loss: 1.9891 , Use Time: 108.67754673957825s\n",
      "Loss_dict : {'loss_all': tensor(0.2627, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2721, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [44/100], Step [200/314], Loss: 0.6615 , Use Time: 144.14672350883484s\n",
      "Loss_dict : {'loss_all': tensor(0.3395, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3329, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [44/100], Step [250/314], Loss: 0.8455 , Use Time: 179.81823801994324s\n",
      "Loss_dict : {'loss_all': tensor(0.2640, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2680, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [44/100], Step [300/314], Loss: 0.6620 , Use Time: 215.25485754013062s\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.0.weight\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.1.weight\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.2.weight\n",
      "Epoch [44/100], Average Loss: 1.0300, 1 Epoch Time 224.4877028465271 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch45\n",
      "Loss_dict : {'loss_all': tensor(0.7343, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.7461, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [45/100], Step [50/314], Loss: 1.8417 , Use Time: 36.01262307167053s\n",
      "Loss_dict : {'loss_all': tensor(0.5968, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.5865, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [45/100], Step [100/314], Loss: 1.4869 , Use Time: 73.04269170761108s\n",
      "Loss_dict : {'loss_all': tensor(0.3150, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3138, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [45/100], Step [150/314], Loss: 0.7869 , Use Time: 109.73163914680481s\n",
      "Loss_dict : {'loss_all': tensor(0.4304, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.4280, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [45/100], Step [200/314], Loss: 1.0749 , Use Time: 149.18040919303894s\n",
      "Loss_dict : {'loss_all': tensor(0.2596, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2593, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [45/100], Step [250/314], Loss: 0.6488 , Use Time: 185.02943587303162s\n",
      "Loss_dict : {'loss_all': tensor(0.2102, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2059, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [45/100], Step [300/314], Loss: 0.5233 , Use Time: 223.52718472480774s\n",
      "Epoch [45/100], Average Loss: 1.0259, 1 Epoch Time 233.11516737937927 s\n",
      "Model 45 Already Saved\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch46\n",
      "Loss_dict : {'loss_all': tensor(0.2334, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2553, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [46/100], Step [50/314], Loss: 0.5945 , Use Time: 38.190650939941406s\n",
      "Loss_dict : {'loss_all': tensor(0.7444, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.7450, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [46/100], Step [100/314], Loss: 1.8613 , Use Time: 74.62382698059082s\n",
      "Loss_dict : {'loss_all': tensor(0.1957, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2046, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [46/100], Step [150/314], Loss: 0.4936 , Use Time: 111.46579384803772s\n",
      "Loss_dict : {'loss_all': tensor(0.2202, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2135, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [46/100], Step [200/314], Loss: 0.5472 , Use Time: 151.60647106170654s\n",
      "Loss_dict : {'loss_all': tensor(0.2530, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2608, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [46/100], Step [250/314], Loss: 0.6364 , Use Time: 190.45633578300476s\n",
      "Loss_dict : {'loss_all': tensor(0.2037, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2131, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [46/100], Step [300/314], Loss: 0.5141 , Use Time: 228.85127139091492s\n",
      "Epoch [46/100], Average Loss: 1.0365, 1 Epoch Time 238.70079946517944 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch47\n",
      "Loss_dict : {'loss_all': tensor(0.5390, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.5269, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [47/100], Step [50/314], Loss: 1.3414 , Use Time: 35.226532220840454s\n",
      "Loss_dict : {'loss_all': tensor(0.7317, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.7488, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [47/100], Step [100/314], Loss: 1.8378 , Use Time: 74.87904286384583s\n",
      "Loss_dict : {'loss_all': tensor(1.1106, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(1.0998, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [47/100], Step [150/314], Loss: 2.7710 , Use Time: 113.6143729686737s\n",
      "Loss_dict : {'loss_all': tensor(0.2737, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2619, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [47/100], Step [200/314], Loss: 0.6784 , Use Time: 160.3980095386505s\n",
      "Loss_dict : {'loss_all': tensor(1.1704, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(1.1722, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [47/100], Step [250/314], Loss: 2.9269 , Use Time: 222.01990413665771s\n",
      "Loss_dict : {'loss_all': tensor(1.2298, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(1.2350, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [47/100], Step [300/314], Loss: 3.0770 , Use Time: 282.15319871902466s\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.1.weight\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.2.weight\n",
      "Epoch [47/100], Average Loss: 1.0318, 1 Epoch Time 296.34159994125366 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch48\n",
      "Loss_dict : {'loss_all': tensor(0.3076, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3056, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [48/100], Step [50/314], Loss: 0.7680 , Use Time: 52.710734367370605s\n",
      "Loss_dict : {'loss_all': tensor(0.2877, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3205, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [48/100], Step [100/314], Loss: 0.7356 , Use Time: 100.61168909072876s\n",
      "Loss_dict : {'loss_all': tensor(0.2745, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2640, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [48/100], Step [150/314], Loss: 0.6811 , Use Time: 150.55713820457458s\n",
      "Loss_dict : {'loss_all': tensor(0.2187, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2161, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [48/100], Step [200/314], Loss: 0.5455 , Use Time: 207.08519768714905s\n",
      "Loss_dict : {'loss_all': tensor(0.3773, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3722, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [48/100], Step [250/314], Loss: 0.9406 , Use Time: 263.67509031295776s\n",
      "Loss_dict : {'loss_all': tensor(0.3634, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3152, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [48/100], Step [300/314], Loss: 0.8844 , Use Time: 311.7714755535126s\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.2.weight\n",
      "Epoch [48/100], Average Loss: 1.0253, 1 Epoch Time 326.74535489082336 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch49\n",
      "Loss_dict : {'loss_all': tensor(0.7129, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.7041, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [49/100], Step [50/314], Loss: 1.7778 , Use Time: 47.59611535072327s\n",
      "Loss_dict : {'loss_all': tensor(0.2220, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2323, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [49/100], Step [100/314], Loss: 0.5602 , Use Time: 95.81081461906433s\n",
      "Loss_dict : {'loss_all': tensor(0.2722, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2731, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [49/100], Step [150/314], Loss: 0.6809 , Use Time: 137.35021042823792s\n",
      "Loss_dict : {'loss_all': tensor(0.2534, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2553, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [49/100], Step [200/314], Loss: 0.6344 , Use Time: 182.06154441833496s\n",
      "Loss_dict : {'loss_all': tensor(0.2670, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2586, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [49/100], Step [250/314], Loss: 0.6633 , Use Time: 223.4269449710846s\n",
      "Loss_dict : {'loss_all': tensor(0.7325, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.7406, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [49/100], Step [300/314], Loss: 1.8353 , Use Time: 266.22607493400574s\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.2.weight\n",
      "Epoch [49/100], Average Loss: 1.0304, 1 Epoch Time 277.0599799156189 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch50\n",
      "Loss_dict : {'loss_all': tensor(2.2969, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(2.2847, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [50/100], Step [50/314], Loss: 5.7362 , Use Time: 35.504809856414795s\n",
      "Loss_dict : {'loss_all': tensor(0.2470, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2433, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [50/100], Step [100/314], Loss: 0.6157 , Use Time: 73.4819884300232s\n",
      "Loss_dict : {'loss_all': tensor(0.4880, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.4931, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [50/100], Step [150/314], Loss: 1.2226 , Use Time: 115.62051630020142s\n",
      "Loss_dict : {'loss_all': tensor(0.2778, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2831, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [50/100], Step [200/314], Loss: 0.6972 , Use Time: 156.80032396316528s\n",
      "Loss_dict : {'loss_all': tensor(0.2503, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2469, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [50/100], Step [250/314], Loss: 0.6240 , Use Time: 199.53786063194275s\n",
      "Loss_dict : {'loss_all': tensor(0.5995, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.6115, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [50/100], Step [300/314], Loss: 1.5047 , Use Time: 237.63689947128296s\n",
      "Epoch [50/100], Average Loss: 1.0276, 1 Epoch Time 248.82903504371643 s\n",
      "Model 50 Already Saved\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch51\n",
      "Loss_dict : {'loss_all': tensor(0.3488, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3486, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [51/100], Step [50/314], Loss: 0.8720 , Use Time: 37.571385860443115s\n",
      "Loss_dict : {'loss_all': tensor(0.2531, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2544, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [51/100], Step [100/314], Loss: 0.6333 , Use Time: 73.95838069915771s\n",
      "Loss_dict : {'loss_all': tensor(0.2421, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2542, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [51/100], Step [150/314], Loss: 0.6114 , Use Time: 111.08009243011475s\n",
      "Loss_dict : {'loss_all': tensor(0.4749, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.4744, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [51/100], Step [200/314], Loss: 1.1870 , Use Time: 150.54355335235596s\n",
      "Loss_dict : {'loss_all': tensor(0.3243, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3141, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [51/100], Step [250/314], Loss: 0.8056 , Use Time: 194.8771185874939s\n",
      "Loss_dict : {'loss_all': tensor(0.2118, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2394, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [51/100], Step [300/314], Loss: 0.5433 , Use Time: 240.33031678199768s\n",
      "Epoch [51/100], Average Loss: 1.0267, 1 Epoch Time 252.22115683555603 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch52\n",
      "Loss_dict : {'loss_all': tensor(0.3803, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3747, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [52/100], Step [50/314], Loss: 0.9479 , Use Time: 39.583942890167236s\n",
      "Loss_dict : {'loss_all': tensor(0.2022, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.1999, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [52/100], Step [100/314], Loss: 0.5043 , Use Time: 81.43565940856934s\n",
      "Loss_dict : {'loss_all': tensor(1.3922, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(1.3854, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [52/100], Step [150/314], Loss: 3.4771 , Use Time: 123.84376215934753s\n",
      "Loss_dict : {'loss_all': tensor(0.2694, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2720, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [52/100], Step [200/314], Loss: 0.6749 , Use Time: 166.9855136871338s\n",
      "Loss_dict : {'loss_all': tensor(1.3757, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(1.3719, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [52/100], Step [250/314], Loss: 3.4373 , Use Time: 207.2722749710083s\n",
      "Loss_dict : {'loss_all': tensor(0.3517, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3178, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [52/100], Step [300/314], Loss: 0.8623 , Use Time: 252.12422800064087s\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.2.weight\n",
      "Epoch [52/100], Average Loss: 1.0318, 1 Epoch Time 265.10591101646423 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch53\n",
      "Loss_dict : {'loss_all': tensor(0.2366, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2308, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [53/100], Step [50/314], Loss: 0.5885 , Use Time: 41.400714635849s\n",
      "Loss_dict : {'loss_all': tensor(0.2331, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2613, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [53/100], Step [100/314], Loss: 0.5968 , Use Time: 85.59025764465332s\n",
      "Loss_dict : {'loss_all': tensor(0.2525, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2394, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [53/100], Step [150/314], Loss: 0.6246 , Use Time: 129.57186937332153s\n",
      "Loss_dict : {'loss_all': tensor(0.7230, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.7437, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [53/100], Step [200/314], Loss: 1.8179 , Use Time: 173.22393560409546s\n",
      "Loss_dict : {'loss_all': tensor(0.2766, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2847, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [53/100], Step [250/314], Loss: 0.6955 , Use Time: 217.4550108909607s\n",
      "Loss_dict : {'loss_all': tensor(0.2847, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2729, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [53/100], Step [300/314], Loss: 0.7059 , Use Time: 255.27672600746155s\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.2.weight\n",
      "Epoch [53/100], Average Loss: 1.0261, 1 Epoch Time 266.78839206695557 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch54\n",
      "Loss_dict : {'loss_all': tensor(2.1479, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(2.1486, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [54/100], Step [50/314], Loss: 5.3702 , Use Time: 36.39107608795166s\n",
      "Loss_dict : {'loss_all': tensor(0.2760, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2689, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [54/100], Step [100/314], Loss: 0.6865 , Use Time: 74.08119320869446s\n",
      "Loss_dict : {'loss_all': tensor(0.2579, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2563, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [54/100], Step [150/314], Loss: 0.6440 , Use Time: 111.15586066246033s\n",
      "Loss_dict : {'loss_all': tensor(0.5015, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.5111, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [54/100], Step [200/314], Loss: 1.2586 , Use Time: 146.93805599212646s\n",
      "Loss_dict : {'loss_all': tensor(0.2059, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2136, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [54/100], Step [250/314], Loss: 0.5186 , Use Time: 183.3189594745636s\n",
      "Loss_dict : {'loss_all': tensor(0.3878, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3794, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [54/100], Step [300/314], Loss: 0.9653 , Use Time: 222.33652591705322s\n",
      "Epoch [54/100], Average Loss: 1.0258, 1 Epoch Time 232.33938479423523 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch55\n",
      "Loss_dict : {'loss_all': tensor(0.2764, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2718, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [55/100], Step [50/314], Loss: 0.6886 , Use Time: 36.207144021987915s\n",
      "Loss_dict : {'loss_all': tensor(0.4795, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.4838, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [55/100], Step [100/314], Loss: 1.2009 , Use Time: 72.81524753570557s\n",
      "Loss_dict : {'loss_all': tensor(0.2957, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3200, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [55/100], Step [150/314], Loss: 0.7513 , Use Time: 109.5210874080658s\n",
      "Loss_dict : {'loss_all': tensor(0.2081, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2178, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [55/100], Step [200/314], Loss: 0.5251 , Use Time: 146.68219423294067s\n",
      "Loss_dict : {'loss_all': tensor(0.2892, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2861, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [55/100], Step [250/314], Loss: 0.7215 , Use Time: 182.2422113418579s\n",
      "Loss_dict : {'loss_all': tensor(0.2070, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2103, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [55/100], Step [300/314], Loss: 0.5192 , Use Time: 217.79681277275085s\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.0.weight\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.1.weight\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.2.weight\n",
      "Epoch [55/100], Average Loss: 1.0300, 1 Epoch Time 227.1162679195404 s\n",
      "Model 55 Already Saved\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch56\n",
      "Loss_dict : {'loss_all': tensor(0.2901, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3045, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [56/100], Step [50/314], Loss: 0.7325 , Use Time: 36.171406984329224s\n",
      "Loss_dict : {'loss_all': tensor(0.4476, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3923, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [56/100], Step [100/314], Loss: 1.0914 , Use Time: 72.42856550216675s\n",
      "Loss_dict : {'loss_all': tensor(0.3705, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3600, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [56/100], Step [150/314], Loss: 0.9211 , Use Time: 108.80627417564392s\n",
      "Loss_dict : {'loss_all': tensor(0.2038, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2205, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [56/100], Step [200/314], Loss: 0.5178 , Use Time: 151.30190014839172s\n",
      "Loss_dict : {'loss_all': tensor(0.9082, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.9075, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [56/100], Step [250/314], Loss: 2.2702 , Use Time: 193.57373905181885s\n",
      "Loss_dict : {'loss_all': tensor(0.1936, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2048, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [56/100], Step [300/314], Loss: 0.4895 , Use Time: 232.87404441833496s\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.1.weight\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.2.weight\n",
      "Epoch [56/100], Average Loss: 1.0287, 1 Epoch Time 243.7965395450592 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch57\n",
      "Loss_dict : {'loss_all': tensor(0.2489, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2430, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [57/100], Step [50/314], Loss: 0.6193 , Use Time: 35.873008728027344s\n",
      "Loss_dict : {'loss_all': tensor(0.2850, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2736, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [57/100], Step [100/314], Loss: 0.7068 , Use Time: 73.83468317985535s\n",
      "Loss_dict : {'loss_all': tensor(0.2737, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2787, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [57/100], Step [150/314], Loss: 0.6868 , Use Time: 112.4284827709198s\n",
      "Loss_dict : {'loss_all': tensor(0.3094, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3286, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [57/100], Step [200/314], Loss: 0.7830 , Use Time: 150.6192455291748s\n",
      "Loss_dict : {'loss_all': tensor(0.4989, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.5065, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [57/100], Step [250/314], Loss: 1.2510 , Use Time: 190.07727551460266s\n",
      "Loss_dict : {'loss_all': tensor(0.2531, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2713, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [57/100], Step [300/314], Loss: 0.6419 , Use Time: 226.57277059555054s\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.1.weight\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.2.weight\n",
      "Epoch [57/100], Average Loss: 1.0618, 1 Epoch Time 236.73200750350952 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch58\n",
      "Loss_dict : {'loss_all': tensor(0.2397, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2586, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [58/100], Step [50/314], Loss: 0.6087 , Use Time: 36.90006160736084s\n",
      "Loss_dict : {'loss_all': tensor(0.6338, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.6666, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [58/100], Step [100/314], Loss: 1.6009 , Use Time: 74.0820517539978s\n",
      "Loss_dict : {'loss_all': tensor(0.2470, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2409, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [58/100], Step [150/314], Loss: 0.6143 , Use Time: 111.18239378929138s\n",
      "Loss_dict : {'loss_all': tensor(0.2489, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2535, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [58/100], Step [200/314], Loss: 0.6246 , Use Time: 148.58638834953308s\n",
      "Loss_dict : {'loss_all': tensor(0.3436, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3266, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [58/100], Step [250/314], Loss: 0.8505 , Use Time: 185.11454963684082s\n",
      "Loss_dict : {'loss_all': tensor(2.2032, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(2.2102, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [58/100], Step [300/314], Loss: 5.5114 , Use Time: 221.84671902656555s\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.2.weight\n",
      "Epoch [58/100], Average Loss: 1.0491, 1 Epoch Time 231.1525948047638 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch59\n",
      "Loss_dict : {'loss_all': tensor(0.1926, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.1944, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [59/100], Step [50/314], Loss: 0.4824 , Use Time: 35.64994716644287s\n",
      "Loss_dict : {'loss_all': tensor(0.7384, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.7358, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [59/100], Step [100/314], Loss: 1.8446 , Use Time: 72.77652359008789s\n",
      "Loss_dict : {'loss_all': tensor(0.2010, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2049, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [59/100], Step [150/314], Loss: 0.5045 , Use Time: 109.32157492637634s\n",
      "Loss_dict : {'loss_all': tensor(0.2870, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2535, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [59/100], Step [200/314], Loss: 0.7008 , Use Time: 144.34416675567627s\n",
      "Loss_dict : {'loss_all': tensor(0.3108, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2943, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [59/100], Step [250/314], Loss: 0.7687 , Use Time: 182.386088848114s\n",
      "Loss_dict : {'loss_all': tensor(0.2447, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2496, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [59/100], Step [300/314], Loss: 0.6142 , Use Time: 218.27584099769592s\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.2.weight\n",
      "Epoch [59/100], Average Loss: 1.0287, 1 Epoch Time 228.2361285686493 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch60\n",
      "Loss_dict : {'loss_all': tensor(0.2177, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2179, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [60/100], Step [50/314], Loss: 0.5443 , Use Time: 36.32178783416748s\n",
      "Loss_dict : {'loss_all': tensor(0.2688, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2860, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [60/100], Step [100/314], Loss: 0.6805 , Use Time: 71.4837760925293s\n",
      "Loss_dict : {'loss_all': tensor(0.2845, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2850, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [60/100], Step [150/314], Loss: 0.7115 , Use Time: 109.95543193817139s\n",
      "Loss_dict : {'loss_all': tensor(0.3028, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3317, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [60/100], Step [200/314], Loss: 0.7715 , Use Time: 147.60713267326355s\n",
      "Loss_dict : {'loss_all': tensor(0.7460, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.7715, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [60/100], Step [250/314], Loss: 1.8778 , Use Time: 184.8113250732422s\n",
      "Loss_dict : {'loss_all': tensor(0.3541, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3552, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [60/100], Step [300/314], Loss: 0.8858 , Use Time: 222.17041444778442s\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.1.weight\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.2.weight\n",
      "Epoch [60/100], Average Loss: 1.0263, 1 Epoch Time 231.9387731552124 s\n",
      "Model 60 Already Saved\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch61\n",
      "Loss_dict : {'loss_all': tensor(1.7606, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(1.7579, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [61/100], Step [50/314], Loss: 4.4002 , Use Time: 37.32943534851074s\n",
      "Loss_dict : {'loss_all': tensor(0.2395, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2414, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [61/100], Step [100/314], Loss: 0.5997 , Use Time: 72.35878109931946s\n",
      "Loss_dict : {'loss_all': tensor(0.5537, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.5581, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [61/100], Step [150/314], Loss: 1.3864 , Use Time: 109.36524987220764s\n",
      "Loss_dict : {'loss_all': tensor(0.2140, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2260, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [61/100], Step [200/314], Loss: 0.5411 , Use Time: 145.693377494812s\n",
      "Loss_dict : {'loss_all': tensor(0.2119, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2214, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [61/100], Step [250/314], Loss: 0.5345 , Use Time: 182.31221055984497s\n",
      "Loss_dict : {'loss_all': tensor(0.5705, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.5859, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [61/100], Step [300/314], Loss: 1.4339 , Use Time: 218.60250616073608s\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.0.weight\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.1.weight\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.2.weight\n",
      "Epoch [61/100], Average Loss: 1.0345, 1 Epoch Time 228.50507998466492 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch62\n",
      "Loss_dict : {'loss_all': tensor(0.3039, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2901, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [62/100], Step [50/314], Loss: 0.7528 , Use Time: 35.742353677749634s\n",
      "Loss_dict : {'loss_all': tensor(0.3190, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3198, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [62/100], Step [100/314], Loss: 0.7979 , Use Time: 71.84205460548401s\n",
      "Loss_dict : {'loss_all': tensor(0.5071, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.4766, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [62/100], Step [150/314], Loss: 1.2525 , Use Time: 107.8515510559082s\n",
      "Loss_dict : {'loss_all': tensor(0.2398, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2674, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [62/100], Step [200/314], Loss: 0.6133 , Use Time: 143.60298252105713s\n",
      "Loss_dict : {'loss_all': tensor(0.2166, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2158, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [62/100], Step [250/314], Loss: 0.5411 , Use Time: 178.80038356781006s\n",
      "Loss_dict : {'loss_all': tensor(0.4109, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3994, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [62/100], Step [300/314], Loss: 1.0215 , Use Time: 217.18152856826782s\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.1.weight\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.2.weight\n",
      "Epoch [62/100], Average Loss: 1.0367, 1 Epoch Time 229.02328968048096 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch63\n",
      "Loss_dict : {'loss_all': tensor(0.2662, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2843, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [63/100], Step [50/314], Loss: 0.6745 , Use Time: 39.85663390159607s\n",
      "Loss_dict : {'loss_all': tensor(0.2553, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2270, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [63/100], Step [100/314], Loss: 0.6240 , Use Time: 76.98136305809021s\n",
      "Loss_dict : {'loss_all': tensor(0.2296, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2525, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [63/100], Step [150/314], Loss: 0.5854 , Use Time: 112.92040657997131s\n",
      "Loss_dict : {'loss_all': tensor(0.2665, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2741, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [63/100], Step [200/314], Loss: 0.6701 , Use Time: 148.21548080444336s\n",
      "Loss_dict : {'loss_all': tensor(0.2491, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2478, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [63/100], Step [250/314], Loss: 0.6220 , Use Time: 185.90964031219482s\n",
      "Loss_dict : {'loss_all': tensor(0.6633, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.7176, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [63/100], Step [300/314], Loss: 1.6853 , Use Time: 223.78624296188354s\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.1.weight\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.2.weight\n",
      "Epoch [63/100], Average Loss: 1.0310, 1 Epoch Time 233.32877445220947 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch64\n",
      "Loss_dict : {'loss_all': tensor(0.3013, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2782, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [64/100], Step [50/314], Loss: 0.7416 , Use Time: 36.153353452682495s\n",
      "Loss_dict : {'loss_all': tensor(0.4127, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.4125, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [64/100], Step [100/314], Loss: 1.0317 , Use Time: 72.42863368988037s\n",
      "Loss_dict : {'loss_all': tensor(0.2132, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2203, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [64/100], Step [150/314], Loss: 0.5365 , Use Time: 108.59125709533691s\n",
      "Loss_dict : {'loss_all': tensor(0.2787, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2722, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [64/100], Step [200/314], Loss: 0.6935 , Use Time: 145.58705735206604s\n",
      "Loss_dict : {'loss_all': tensor(0.2379, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2262, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [64/100], Step [250/314], Loss: 0.5890 , Use Time: 181.49800419807434s\n",
      "Loss_dict : {'loss_all': tensor(0.2609, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2642, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [64/100], Step [300/314], Loss: 0.6539 , Use Time: 217.46174502372742s\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.1.weight\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.2.weight\n",
      "Epoch [64/100], Average Loss: 1.0435, 1 Epoch Time 227.69456100463867 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch65\n",
      "Loss_dict : {'loss_all': tensor(0.2927, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2891, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [65/100], Step [50/314], Loss: 0.7298 , Use Time: 39.61335563659668s\n",
      "Loss_dict : {'loss_all': tensor(0.2727, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2683, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [65/100], Step [100/314], Loss: 0.6796 , Use Time: 84.77196979522705s\n",
      "Loss_dict : {'loss_all': tensor(0.4469, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.4360, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [65/100], Step [150/314], Loss: 1.1117 , Use Time: 129.61407828330994s\n",
      "Loss_dict : {'loss_all': tensor(0.2283, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2500, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [65/100], Step [200/314], Loss: 0.5816 , Use Time: 167.53086876869202s\n",
      "Loss_dict : {'loss_all': tensor(0.2110, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2261, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [65/100], Step [250/314], Loss: 0.5350 , Use Time: 204.12712788581848s\n",
      "Loss_dict : {'loss_all': tensor(0.3814, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3886, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [65/100], Step [300/314], Loss: 0.9571 , Use Time: 240.22618341445923s\n",
      "Epoch [65/100], Average Loss: 1.0229, 1 Epoch Time 249.44574403762817 s\n",
      "Model 65 Already Saved\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch66\n",
      "Loss_dict : {'loss_all': tensor(0.2519, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2394, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [66/100], Step [50/314], Loss: 0.6235 , Use Time: 35.037842988967896s\n",
      "Loss_dict : {'loss_all': tensor(0.2460, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2376, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [66/100], Step [100/314], Loss: 0.6109 , Use Time: 70.9275496006012s\n",
      "Loss_dict : {'loss_all': tensor(0.2843, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2832, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [66/100], Step [150/314], Loss: 0.7102 , Use Time: 107.15028381347656s\n",
      "Loss_dict : {'loss_all': tensor(1.1236, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(1.1419, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [66/100], Step [200/314], Loss: 2.8182 , Use Time: 144.63796877861023s\n",
      "Loss_dict : {'loss_all': tensor(0.2457, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2437, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [66/100], Step [250/314], Loss: 0.6132 , Use Time: 181.49276399612427s\n",
      "Loss_dict : {'loss_all': tensor(0.3067, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3103, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [66/100], Step [300/314], Loss: 0.7685 , Use Time: 218.63168382644653s\n",
      "Epoch [66/100], Average Loss: 1.0266, 1 Epoch Time 228.9341459274292 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch67\n",
      "Loss_dict : {'loss_all': tensor(0.8980, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.9024, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [67/100], Step [50/314], Loss: 2.2472 , Use Time: 37.1792197227478s\n",
      "Loss_dict : {'loss_all': tensor(0.2470, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2643, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [67/100], Step [100/314], Loss: 0.6262 , Use Time: 75.1586389541626s\n",
      "Loss_dict : {'loss_all': tensor(0.7962, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.8088, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [67/100], Step [150/314], Loss: 1.9969 , Use Time: 111.9279294013977s\n",
      "Loss_dict : {'loss_all': tensor(0.2205, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2278, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [67/100], Step [200/314], Loss: 0.5550 , Use Time: 147.52302265167236s\n",
      "Loss_dict : {'loss_all': tensor(0.2600, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2504, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [67/100], Step [250/314], Loss: 0.6453 , Use Time: 183.3646116256714s\n",
      "Loss_dict : {'loss_all': tensor(0.4967, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.5156, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [67/100], Step [300/314], Loss: 1.2512 , Use Time: 224.05666971206665s\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.1.weight\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.2.weight\n",
      "Epoch [67/100], Average Loss: 1.0351, 1 Epoch Time 235.40524673461914 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch68\n",
      "Loss_dict : {'loss_all': tensor(0.3849, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3797, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [68/100], Step [50/314], Loss: 0.9596 , Use Time: 39.85299372673035s\n",
      "Loss_dict : {'loss_all': tensor(0.6150, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.6392, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [68/100], Step [100/314], Loss: 1.5495 , Use Time: 80.2604455947876s\n",
      "Loss_dict : {'loss_all': tensor(0.9604, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.9638, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [68/100], Step [150/314], Loss: 2.4027 , Use Time: 115.74653100967407s\n",
      "Loss_dict : {'loss_all': tensor(0.3382, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3291, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [68/100], Step [200/314], Loss: 0.8410 , Use Time: 151.07494711875916s\n",
      "Loss_dict : {'loss_all': tensor(0.2532, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2533, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [68/100], Step [250/314], Loss: 0.6331 , Use Time: 187.5673267841339s\n",
      "Loss_dict : {'loss_all': tensor(0.2268, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2494, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [68/100], Step [300/314], Loss: 0.5784 , Use Time: 223.47871947288513s\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.2.weight\n",
      "Epoch [68/100], Average Loss: 1.0279, 1 Epoch Time 233.36887955665588 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch69\n",
      "Loss_dict : {'loss_all': tensor(0.3309, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3201, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [69/100], Step [50/314], Loss: 0.8219 , Use Time: 36.28136205673218s\n",
      "Loss_dict : {'loss_all': tensor(0.4218, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.4307, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [69/100], Step [100/314], Loss: 1.0590 , Use Time: 71.90205931663513s\n",
      "Loss_dict : {'loss_all': tensor(0.2774, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2853, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [69/100], Step [150/314], Loss: 0.6975 , Use Time: 108.49503374099731s\n",
      "Loss_dict : {'loss_all': tensor(0.4438, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.4466, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [69/100], Step [200/314], Loss: 1.1109 , Use Time: 149.8087923526764s\n",
      "Loss_dict : {'loss_all': tensor(0.2514, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2416, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [69/100], Step [250/314], Loss: 0.6236 , Use Time: 186.9480013847351s\n",
      "Loss_dict : {'loss_all': tensor(0.4886, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.5025, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [69/100], Step [300/314], Loss: 1.2284 , Use Time: 224.71042490005493s\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.2.weight\n",
      "Epoch [69/100], Average Loss: 1.0289, 1 Epoch Time 234.5580976009369 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch70\n",
      "Loss_dict : {'loss_all': tensor(0.4032, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.4262, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [70/100], Step [50/314], Loss: 1.0195 , Use Time: 36.73769783973694s\n",
      "Loss_dict : {'loss_all': tensor(0.2373, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2340, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [70/100], Step [100/314], Loss: 0.5916 , Use Time: 72.57073163986206s\n",
      "Loss_dict : {'loss_all': tensor(0.2786, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2597, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [70/100], Step [150/314], Loss: 0.6870 , Use Time: 111.20369410514832s\n",
      "Loss_dict : {'loss_all': tensor(0.3337, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3283, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [70/100], Step [200/314], Loss: 0.8316 , Use Time: 149.9543628692627s\n",
      "Loss_dict : {'loss_all': tensor(0.7159, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.7194, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [70/100], Step [250/314], Loss: 1.7915 , Use Time: 189.79658007621765s\n",
      "Loss_dict : {'loss_all': tensor(0.2188, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2255, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [70/100], Step [300/314], Loss: 0.5503 , Use Time: 227.10900974273682s\n",
      "Epoch [70/100], Average Loss: 1.0307, 1 Epoch Time 236.4043312072754 s\n",
      "Model 70 Already Saved\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch71\n",
      "Loss_dict : {'loss_all': tensor(1.0317, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(1.0334, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [71/100], Step [50/314], Loss: 2.5801 , Use Time: 36.67339825630188s\n",
      "Loss_dict : {'loss_all': tensor(0.2251, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2347, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [71/100], Step [100/314], Loss: 0.5676 , Use Time: 73.08264470100403s\n",
      "Loss_dict : {'loss_all': tensor(0.2138, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2220, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [71/100], Step [150/314], Loss: 0.5387 , Use Time: 113.00399732589722s\n",
      "Loss_dict : {'loss_all': tensor(0.3487, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3291, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [71/100], Step [200/314], Loss: 0.8619 , Use Time: 150.6422142982483s\n",
      "Loss_dict : {'loss_all': tensor(0.2677, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2856, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [71/100], Step [250/314], Loss: 0.6781 , Use Time: 187.3866355419159s\n",
      "Loss_dict : {'loss_all': tensor(0.2396, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2380, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [71/100], Step [300/314], Loss: 0.5981 , Use Time: 224.74836444854736s\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.1.weight\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.2.weight\n",
      "Epoch [71/100], Average Loss: 1.0224, 1 Epoch Time 235.15523505210876 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch72\n",
      "Loss_dict : {'loss_all': tensor(0.3515, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3479, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [72/100], Step [50/314], Loss: 0.8770 , Use Time: 42.09475874900818s\n",
      "Loss_dict : {'loss_all': tensor(0.2371, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2454, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [72/100], Step [100/314], Loss: 0.5969 , Use Time: 79.04727339744568s\n",
      "Loss_dict : {'loss_all': tensor(1.0788, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(1.0823, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [72/100], Step [150/314], Loss: 2.6987 , Use Time: 116.3573248386383s\n",
      "Loss_dict : {'loss_all': tensor(0.4982, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.5035, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [72/100], Step [200/314], Loss: 1.2481 , Use Time: 152.09712600708008s\n",
      "Loss_dict : {'loss_all': tensor(0.3619, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3799, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [72/100], Step [250/314], Loss: 0.9136 , Use Time: 189.70080089569092s\n",
      "Loss_dict : {'loss_all': tensor(0.2025, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2156, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [72/100], Step [300/314], Loss: 0.5128 , Use Time: 225.44957304000854s\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.2.weight\n",
      "Epoch [72/100], Average Loss: 1.0269, 1 Epoch Time 234.81498837471008 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch73\n",
      "Loss_dict : {'loss_all': tensor(0.3640, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3504, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [73/100], Step [50/314], Loss: 0.9032 , Use Time: 37.803001403808594s\n",
      "Loss_dict : {'loss_all': tensor(0.5330, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.5285, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [73/100], Step [100/314], Loss: 1.3303 , Use Time: 78.8270492553711s\n",
      "Loss_dict : {'loss_all': tensor(0.1863, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.1977, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [73/100], Step [150/314], Loss: 0.4715 , Use Time: 118.06943845748901s\n",
      "Loss_dict : {'loss_all': tensor(0.6357, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.6341, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [73/100], Step [200/314], Loss: 1.5885 , Use Time: 153.7511956691742s\n",
      "Loss_dict : {'loss_all': tensor(0.9084, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.9000, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [73/100], Step [250/314], Loss: 2.2667 , Use Time: 189.85276627540588s\n",
      "Loss_dict : {'loss_all': tensor(0.4032, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3992, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [73/100], Step [300/314], Loss: 1.0061 , Use Time: 225.61689615249634s\n",
      "Epoch [73/100], Average Loss: 1.0256, 1 Epoch Time 235.58365678787231 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch74\n",
      "Loss_dict : {'loss_all': tensor(0.2340, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2513, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [74/100], Step [50/314], Loss: 0.5935 , Use Time: 34.95651388168335s\n",
      "Loss_dict : {'loss_all': tensor(0.3526, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3474, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [74/100], Step [100/314], Loss: 0.8789 , Use Time: 70.41680550575256s\n",
      "Loss_dict : {'loss_all': tensor(0.2435, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2551, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [74/100], Step [150/314], Loss: 0.6146 , Use Time: 106.47977042198181s\n",
      "Loss_dict : {'loss_all': tensor(0.2997, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2845, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [74/100], Step [200/314], Loss: 0.7416 , Use Time: 142.43519067764282s\n",
      "Loss_dict : {'loss_all': tensor(0.3050, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3066, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [74/100], Step [250/314], Loss: 0.7633 , Use Time: 179.76150512695312s\n",
      "Loss_dict : {'loss_all': tensor(0.3370, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3164, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [74/100], Step [300/314], Loss: 0.8323 , Use Time: 216.5867040157318s\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.1.weight\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.2.weight\n",
      "Epoch [74/100], Average Loss: 1.0290, 1 Epoch Time 227.47274565696716 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch75\n",
      "Loss_dict : {'loss_all': tensor(0.2315, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2340, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [75/100], Step [50/314], Loss: 0.5799 , Use Time: 38.26083040237427s\n",
      "Loss_dict : {'loss_all': tensor(0.2430, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2524, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [75/100], Step [100/314], Loss: 0.6123 , Use Time: 74.80780482292175s\n",
      "Loss_dict : {'loss_all': tensor(0.2227, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2160, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [75/100], Step [150/314], Loss: 0.5533 , Use Time: 111.25283980369568s\n",
      "Loss_dict : {'loss_all': tensor(0.2711, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2746, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [75/100], Step [200/314], Loss: 0.6796 , Use Time: 147.88120222091675s\n",
      "Loss_dict : {'loss_all': tensor(0.6484, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.6600, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [75/100], Step [250/314], Loss: 1.6268 , Use Time: 183.57039594650269s\n",
      "Loss_dict : {'loss_all': tensor(0.3627, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3675, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [75/100], Step [300/314], Loss: 0.9091 , Use Time: 219.63982915878296s\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.2.weight\n",
      "Epoch [75/100], Average Loss: 1.0192, 1 Epoch Time 229.4930076599121 s\n",
      "Model 75 Already Saved\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch76\n",
      "Loss_dict : {'loss_all': tensor(0.2683, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2640, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [76/100], Step [50/314], Loss: 0.6687 , Use Time: 35.792962074279785s\n",
      "Loss_dict : {'loss_all': tensor(0.2264, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2246, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [76/100], Step [100/314], Loss: 0.5651 , Use Time: 71.50491452217102s\n",
      "Loss_dict : {'loss_all': tensor(0.2520, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2420, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [76/100], Step [150/314], Loss: 0.6251 , Use Time: 107.57696008682251s\n",
      "Loss_dict : {'loss_all': tensor(0.5516, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.5520, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [76/100], Step [200/314], Loss: 1.3792 , Use Time: 145.31166625022888s\n",
      "Loss_dict : {'loss_all': tensor(0.4111, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.4112, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [76/100], Step [250/314], Loss: 1.0279 , Use Time: 182.1921808719635s\n",
      "Loss_dict : {'loss_all': tensor(0.4221, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.4368, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [76/100], Step [300/314], Loss: 1.0626 , Use Time: 220.95996236801147s\n",
      "Epoch [76/100], Average Loss: 1.0250, 1 Epoch Time 231.60953426361084 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch77\n",
      "Loss_dict : {'loss_all': tensor(0.4552, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.4643, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [77/100], Step [50/314], Loss: 1.1425 , Use Time: 37.34676146507263s\n",
      "Loss_dict : {'loss_all': tensor(0.3330, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3367, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [77/100], Step [100/314], Loss: 0.8343 , Use Time: 74.24528455734253s\n",
      "Loss_dict : {'loss_all': tensor(0.2733, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2697, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [77/100], Step [150/314], Loss: 0.6814 , Use Time: 109.97281432151794s\n",
      "Loss_dict : {'loss_all': tensor(0.2769, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2671, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [77/100], Step [200/314], Loss: 0.6872 , Use Time: 146.12211728096008s\n",
      "Loss_dict : {'loss_all': tensor(0.3168, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3081, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [77/100], Step [250/314], Loss: 0.7877 , Use Time: 185.022718667984s\n",
      "Loss_dict : {'loss_all': tensor(0.3642, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3411, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [77/100], Step [300/314], Loss: 0.8989 , Use Time: 222.9592306613922s\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.1.weight\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.2.weight\n",
      "Epoch [77/100], Average Loss: 1.0169, 1 Epoch Time 232.91782307624817 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch78\n",
      "Loss_dict : {'loss_all': tensor(0.6718, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.6935, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [78/100], Step [50/314], Loss: 1.6903 , Use Time: 36.4765567779541s\n",
      "Loss_dict : {'loss_all': tensor(0.2077, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2282, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [78/100], Step [100/314], Loss: 0.5296 , Use Time: 74.33288478851318s\n",
      "Loss_dict : {'loss_all': tensor(0.3267, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3415, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [78/100], Step [150/314], Loss: 0.8241 , Use Time: 112.78959131240845s\n",
      "Loss_dict : {'loss_all': tensor(0.2218, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2256, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [78/100], Step [200/314], Loss: 0.5564 , Use Time: 152.1984145641327s\n",
      "Loss_dict : {'loss_all': tensor(0.2673, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2860, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [78/100], Step [250/314], Loss: 0.6776 , Use Time: 188.85152196884155s\n",
      "Loss_dict : {'loss_all': tensor(0.4189, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.4133, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [78/100], Step [300/314], Loss: 1.0445 , Use Time: 225.62183809280396s\n",
      "Epoch [78/100], Average Loss: 1.0300, 1 Epoch Time 234.81660890579224 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch79\n",
      "Loss_dict : {'loss_all': tensor(0.6015, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.5612, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [79/100], Step [50/314], Loss: 1.4837 , Use Time: 35.620341062545776s\n",
      "Loss_dict : {'loss_all': tensor(0.2746, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3151, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [79/100], Step [100/314], Loss: 0.7068 , Use Time: 74.10558938980103s\n",
      "Loss_dict : {'loss_all': tensor(0.2688, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2673, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [79/100], Step [150/314], Loss: 0.6713 , Use Time: 110.37666010856628s\n",
      "Loss_dict : {'loss_all': tensor(0.1899, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.1863, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [79/100], Step [200/314], Loss: 0.4730 , Use Time: 146.82253241539001s\n",
      "Loss_dict : {'loss_all': tensor(0.3967, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3223, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [79/100], Step [250/314], Loss: 0.9545 , Use Time: 183.19168996810913s\n",
      "Loss_dict : {'loss_all': tensor(0.2475, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2515, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [79/100], Step [300/314], Loss: 0.6207 , Use Time: 219.64795875549316s\n",
      "Epoch [79/100], Average Loss: 1.0230, 1 Epoch Time 229.15690231323242 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch80\n",
      "Loss_dict : {'loss_all': tensor(0.3006, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2989, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [80/100], Step [50/314], Loss: 0.7507 , Use Time: 36.031116008758545s\n",
      "Loss_dict : {'loss_all': tensor(0.3968, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.4012, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [80/100], Step [100/314], Loss: 0.9943 , Use Time: 72.74590468406677s\n",
      "Loss_dict : {'loss_all': tensor(0.2922, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2964, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [80/100], Step [150/314], Loss: 0.7327 , Use Time: 108.39577770233154s\n",
      "Loss_dict : {'loss_all': tensor(0.1912, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.1966, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [80/100], Step [200/314], Loss: 0.4807 , Use Time: 144.50562453269958s\n",
      "Loss_dict : {'loss_all': tensor(0.3031, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2822, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [80/100], Step [250/314], Loss: 0.7474 , Use Time: 180.41230082511902s\n",
      "Loss_dict : {'loss_all': tensor(2.4739, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(2.4635, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [80/100], Step [300/314], Loss: 6.1796 , Use Time: 217.83896017074585s\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.0.weight\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.1.weight\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.2.weight\n",
      "Epoch [80/100], Average Loss: 1.0276, 1 Epoch Time 227.56072664260864 s\n",
      "Model 80 Already Saved\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch81\n",
      "Loss_dict : {'loss_all': tensor(0.3300, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3452, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [81/100], Step [50/314], Loss: 0.8326 , Use Time: 39.2880539894104s\n",
      "Loss_dict : {'loss_all': tensor(0.2604, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2629, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [81/100], Step [100/314], Loss: 0.6522 , Use Time: 77.97907376289368s\n",
      "Loss_dict : {'loss_all': tensor(0.2550, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2542, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [81/100], Step [150/314], Loss: 0.6372 , Use Time: 115.02642822265625s\n",
      "Loss_dict : {'loss_all': tensor(0.2720, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2908, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [81/100], Step [200/314], Loss: 0.6895 , Use Time: 151.60298776626587s\n",
      "Loss_dict : {'loss_all': tensor(0.1863, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2130, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [81/100], Step [250/314], Loss: 0.4791 , Use Time: 188.02165842056274s\n",
      "Loss_dict : {'loss_all': tensor(0.2613, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2585, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [81/100], Step [300/314], Loss: 0.6518 , Use Time: 224.87027049064636s\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.1.weight\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.2.weight\n",
      "Epoch [81/100], Average Loss: 1.0323, 1 Epoch Time 234.2916009426117 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch82\n",
      "Loss_dict : {'loss_all': tensor(0.5856, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.5901, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [82/100], Step [50/314], Loss: 1.4662 , Use Time: 37.08657693862915s\n",
      "Loss_dict : {'loss_all': tensor(0.3160, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3097, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [82/100], Step [100/314], Loss: 0.7869 , Use Time: 73.10400581359863s\n",
      "Loss_dict : {'loss_all': tensor(0.2663, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2920, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [82/100], Step [150/314], Loss: 0.6787 , Use Time: 110.57468223571777s\n",
      "Loss_dict : {'loss_all': tensor(0.5765, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.5792, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [82/100], Step [200/314], Loss: 1.4426 , Use Time: 148.11568140983582s\n",
      "Loss_dict : {'loss_all': tensor(0.2000, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.1923, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [82/100], Step [250/314], Loss: 0.4961 , Use Time: 185.22091937065125s\n",
      "Loss_dict : {'loss_all': tensor(0.5325, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.5254, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [82/100], Step [300/314], Loss: 1.3278 , Use Time: 223.52254104614258s\n",
      "Epoch [82/100], Average Loss: 1.0302, 1 Epoch Time 233.45335006713867 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch83\n",
      "Loss_dict : {'loss_all': tensor(0.2164, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2172, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [83/100], Step [50/314], Loss: 0.5413 , Use Time: 36.59726905822754s\n",
      "Loss_dict : {'loss_all': tensor(0.4509, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.4529, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [83/100], Step [100/314], Loss: 1.1282 , Use Time: 73.17557120323181s\n",
      "Loss_dict : {'loss_all': tensor(0.2776, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2736, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [83/100], Step [150/314], Loss: 0.6920 , Use Time: 109.46125149726868s\n",
      "Loss_dict : {'loss_all': tensor(0.2680, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2591, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [83/100], Step [200/314], Loss: 0.6655 , Use Time: 146.65972924232483s\n",
      "Loss_dict : {'loss_all': tensor(0.3931, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3644, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [83/100], Step [250/314], Loss: 0.9684 , Use Time: 184.8571629524231s\n",
      "Loss_dict : {'loss_all': tensor(0.4641, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.4596, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [83/100], Step [300/314], Loss: 1.1580 , Use Time: 221.7735002040863s\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.1.weight\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.2.weight\n",
      "Epoch [83/100], Average Loss: 1.0250, 1 Epoch Time 231.46347761154175 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch84\n",
      "Loss_dict : {'loss_all': tensor(0.5024, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.5038, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [84/100], Step [50/314], Loss: 1.2567 , Use Time: 36.36668634414673s\n",
      "Loss_dict : {'loss_all': tensor(0.5045, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.5163, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [84/100], Step [100/314], Loss: 1.2671 , Use Time: 73.52343797683716s\n",
      "Loss_dict : {'loss_all': tensor(0.4091, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.4124, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [84/100], Step [150/314], Loss: 1.0245 , Use Time: 110.88859343528748s\n",
      "Loss_dict : {'loss_all': tensor(0.2853, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2723, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [84/100], Step [200/314], Loss: 0.7067 , Use Time: 150.21489572525024s\n",
      "Loss_dict : {'loss_all': tensor(0.9629, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.9701, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [84/100], Step [250/314], Loss: 2.4108 , Use Time: 186.76685428619385s\n",
      "Loss_dict : {'loss_all': tensor(0.2296, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2386, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [84/100], Step [300/314], Loss: 0.5785 , Use Time: 222.16733264923096s\n",
      "Epoch [84/100], Average Loss: 1.0264, 1 Epoch Time 231.86009573936462 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch85\n",
      "Loss_dict : {'loss_all': tensor(0.2728, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2669, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [85/100], Step [50/314], Loss: 0.6791 , Use Time: 36.413527727127075s\n",
      "Loss_dict : {'loss_all': tensor(0.1526, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.1735, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [85/100], Step [100/314], Loss: 0.3920 , Use Time: 71.48691511154175s\n",
      "Loss_dict : {'loss_all': tensor(0.3121, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3174, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [85/100], Step [150/314], Loss: 0.7830 , Use Time: 107.23620057106018s\n",
      "Loss_dict : {'loss_all': tensor(0.2818, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2817, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [85/100], Step [200/314], Loss: 0.7045 , Use Time: 143.14546275138855s\n",
      "Loss_dict : {'loss_all': tensor(0.2409, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2358, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [85/100], Step [250/314], Loss: 0.5997 , Use Time: 179.26778364181519s\n",
      "Loss_dict : {'loss_all': tensor(0.3308, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3298, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [85/100], Step [300/314], Loss: 0.8266 , Use Time: 216.79358220100403s\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.1.weight\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.2.weight\n",
      "Epoch [85/100], Average Loss: 1.0130, 1 Epoch Time 227.24639225006104 s\n",
      "Model 85 Already Saved\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch86\n",
      "Loss_dict : {'loss_all': tensor(0.4239, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.4220, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [86/100], Step [50/314], Loss: 1.0587 , Use Time: 35.90721821784973s\n",
      "Loss_dict : {'loss_all': tensor(0.2345, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2270, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [86/100], Step [100/314], Loss: 0.5825 , Use Time: 72.46804785728455s\n",
      "Loss_dict : {'loss_all': tensor(0.3091, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3268, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [86/100], Step [150/314], Loss: 0.7816 , Use Time: 108.65891361236572s\n",
      "Loss_dict : {'loss_all': tensor(0.8304, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.8331, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [86/100], Step [200/314], Loss: 2.0773 , Use Time: 144.52008724212646s\n",
      "Loss_dict : {'loss_all': tensor(0.2404, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2305, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [86/100], Step [250/314], Loss: 0.5961 , Use Time: 181.45255064964294s\n",
      "Step275Warning: Gradient vanishing detected in layer crnet.mce.getf1.2.weight\n",
      "Loss_dict : {'loss_all': tensor(0.2436, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2355, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [86/100], Step [300/314], Loss: 0.6049 , Use Time: 218.7609190940857s\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.1.weight\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.2.weight\n",
      "Epoch [86/100], Average Loss: 1.0292, 1 Epoch Time 228.52983140945435 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch87\n",
      "Loss_dict : {'loss_all': tensor(0.2288, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2261, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [87/100], Step [50/314], Loss: 0.5706 , Use Time: 36.72451305389404s\n",
      "Loss_dict : {'loss_all': tensor(0.1862, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.1905, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [87/100], Step [100/314], Loss: 0.4676 , Use Time: 75.47365093231201s\n",
      "Loss_dict : {'loss_all': tensor(0.4434, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.4181, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [87/100], Step [150/314], Loss: 1.0959 , Use Time: 112.6475932598114s\n",
      "Loss_dict : {'loss_all': tensor(0.2037, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2016, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [87/100], Step [200/314], Loss: 0.5081 , Use Time: 151.67366433143616s\n",
      "Loss_dict : {'loss_all': tensor(0.2697, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2461, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [87/100], Step [250/314], Loss: 0.6625 , Use Time: 189.02771019935608s\n",
      "Loss_dict : {'loss_all': tensor(0.4846, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.4950, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [87/100], Step [300/314], Loss: 1.2167 , Use Time: 225.39828944206238s\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.1.weight\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.2.weight\n",
      "Epoch [87/100], Average Loss: 1.0247, 1 Epoch Time 235.06112694740295 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch88\n",
      "Loss_dict : {'loss_all': tensor(0.2344, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2231, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [88/100], Step [50/314], Loss: 0.5803 , Use Time: 36.00084733963013s\n",
      "Loss_dict : {'loss_all': tensor(0.5391, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.5639, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [88/100], Step [100/314], Loss: 1.3601 , Use Time: 72.33390188217163s\n",
      "Loss_dict : {'loss_all': tensor(0.2003, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2145, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [88/100], Step [150/314], Loss: 0.5079 , Use Time: 111.51047706604004s\n",
      "Loss_dict : {'loss_all': tensor(0.3045, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3107, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [88/100], Step [200/314], Loss: 0.7644 , Use Time: 148.9968225955963s\n",
      "Loss_dict : {'loss_all': tensor(0.2437, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2616, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [88/100], Step [250/314], Loss: 0.6182 , Use Time: 184.02067303657532s\n",
      "Loss_dict : {'loss_all': tensor(0.2337, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2412, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [88/100], Step [300/314], Loss: 0.5880 , Use Time: 220.9072687625885s\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.2.weight\n",
      "Epoch [88/100], Average Loss: 1.0262, 1 Epoch Time 231.41513323783875 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch89\n",
      "Loss_dict : {'loss_all': tensor(0.4094, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3523, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [89/100], Step [50/314], Loss: 0.9949 , Use Time: 36.75165152549744s\n",
      "Loss_dict : {'loss_all': tensor(0.2721, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2693, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [89/100], Step [100/314], Loss: 0.6788 , Use Time: 72.44450759887695s\n",
      "Loss_dict : {'loss_all': tensor(0.3141, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3115, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [89/100], Step [150/314], Loss: 0.7840 , Use Time: 108.29377508163452s\n",
      "Loss_dict : {'loss_all': tensor(0.3867, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3866, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [89/100], Step [200/314], Loss: 0.9667 , Use Time: 144.71710515022278s\n",
      "Loss_dict : {'loss_all': tensor(0.2260, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2557, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [89/100], Step [250/314], Loss: 0.5798 , Use Time: 180.2396056652069s\n",
      "Loss_dict : {'loss_all': tensor(0.5747, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.5676, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [89/100], Step [300/314], Loss: 1.4333 , Use Time: 215.8766827583313s\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.1.weight\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.2.weight\n",
      "Epoch [89/100], Average Loss: 1.0219, 1 Epoch Time 225.17067074775696 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch90\n",
      "Loss_dict : {'loss_all': tensor(0.2849, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3004, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [90/100], Step [50/314], Loss: 0.7199 , Use Time: 37.771315574645996s\n",
      "Loss_dict : {'loss_all': tensor(0.3449, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3411, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [90/100], Step [100/314], Loss: 0.8605 , Use Time: 74.96755647659302s\n",
      "Loss_dict : {'loss_all': tensor(0.2290, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2491, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [90/100], Step [150/314], Loss: 0.5826 , Use Time: 110.66603398323059s\n",
      "Loss_dict : {'loss_all': tensor(0.2312, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2399, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [90/100], Step [200/314], Loss: 0.5824 , Use Time: 146.47775602340698s\n",
      "Loss_dict : {'loss_all': tensor(0.2454, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2353, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [90/100], Step [250/314], Loss: 0.6085 , Use Time: 182.22457671165466s\n",
      "Loss_dict : {'loss_all': tensor(0.7012, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.7033, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [90/100], Step [300/314], Loss: 1.7541 , Use Time: 218.04331994056702s\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.1.weight\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.2.weight\n",
      "Epoch [90/100], Average Loss: 1.0333, 1 Epoch Time 227.61143159866333 s\n",
      "Model 90 Already Saved\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch91\n",
      "Loss_dict : {'loss_all': tensor(0.3280, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3369, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [91/100], Step [50/314], Loss: 0.8244 , Use Time: 35.83974814414978s\n",
      "Loss_dict : {'loss_all': tensor(0.2313, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2579, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [91/100], Step [100/314], Loss: 0.5916 , Use Time: 71.76483201980591s\n",
      "Loss_dict : {'loss_all': tensor(0.2744, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2821, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [91/100], Step [150/314], Loss: 0.6898 , Use Time: 108.81748986244202s\n",
      "Loss_dict : {'loss_all': tensor(0.2693, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2611, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [91/100], Step [200/314], Loss: 0.6691 , Use Time: 147.01669907569885s\n",
      "Loss_dict : {'loss_all': tensor(0.1916, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.1906, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [91/100], Step [250/314], Loss: 0.4785 , Use Time: 186.23464584350586s\n",
      "Loss_dict : {'loss_all': tensor(0.2077, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2161, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [91/100], Step [300/314], Loss: 0.5235 , Use Time: 223.2961037158966s\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.0.weight\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.1.weight\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.2.weight\n",
      "Epoch [91/100], Average Loss: 1.0301, 1 Epoch Time 232.66386938095093 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch92\n",
      "Loss_dict : {'loss_all': tensor(0.2698, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2713, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [92/100], Step [50/314], Loss: 0.6754 , Use Time: 35.57277822494507s\n",
      "Loss_dict : {'loss_all': tensor(0.2761, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2866, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [92/100], Step [100/314], Loss: 0.6954 , Use Time: 71.38790845870972s\n",
      "Loss_dict : {'loss_all': tensor(0.6273, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.6227, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [92/100], Step [150/314], Loss: 1.5659 , Use Time: 106.65455889701843s\n",
      "Loss_dict : {'loss_all': tensor(0.3134, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3368, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [92/100], Step [200/314], Loss: 0.7953 , Use Time: 142.1410267353058s\n",
      "Loss_dict : {'loss_all': tensor(0.2691, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2690, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [92/100], Step [250/314], Loss: 0.6727 , Use Time: 178.76551175117493s\n",
      "Loss_dict : {'loss_all': tensor(0.8803, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.8797, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [92/100], Step [300/314], Loss: 2.2005 , Use Time: 214.85671019554138s\n",
      "Epoch [92/100], Average Loss: 1.0252, 1 Epoch Time 224.39358162879944 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch93\n",
      "Loss_dict : {'loss_all': tensor(0.9951, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(1.0022, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [93/100], Step [50/314], Loss: 2.4913 , Use Time: 35.764575481414795s\n",
      "Loss_dict : {'loss_all': tensor(0.2185, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2320, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [93/100], Step [100/314], Loss: 0.5529 , Use Time: 71.14765405654907s\n",
      "Loss_dict : {'loss_all': tensor(0.2071, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2159, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [93/100], Step [150/314], Loss: 0.5222 , Use Time: 106.86984491348267s\n",
      "Loss_dict : {'loss_all': tensor(0.4719, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.4863, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [93/100], Step [200/314], Loss: 1.1870 , Use Time: 142.04921627044678s\n",
      "Loss_dict : {'loss_all': tensor(0.2584, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2658, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [93/100], Step [250/314], Loss: 0.6497 , Use Time: 177.8327877521515s\n",
      "Loss_dict : {'loss_all': tensor(0.8552, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.8575, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [93/100], Step [300/314], Loss: 2.1390 , Use Time: 214.94845461845398s\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.1.weight\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.2.weight\n",
      "Epoch [93/100], Average Loss: 1.0182, 1 Epoch Time 224.70007944107056 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch94\n",
      "Loss_dict : {'loss_all': tensor(0.5882, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.6112, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [94/100], Step [50/314], Loss: 1.4820 , Use Time: 39.221107959747314s\n",
      "Loss_dict : {'loss_all': tensor(0.3319, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3325, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [94/100], Step [100/314], Loss: 0.8300 , Use Time: 76.4549150466919s\n",
      "Loss_dict : {'loss_all': tensor(0.4160, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3920, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [94/100], Step [150/314], Loss: 1.0279 , Use Time: 114.3791573047638s\n",
      "Loss_dict : {'loss_all': tensor(0.3126, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3063, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [94/100], Step [200/314], Loss: 0.7783 , Use Time: 151.9761254787445s\n",
      "Loss_dict : {'loss_all': tensor(0.2345, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2328, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [94/100], Step [250/314], Loss: 0.5854 , Use Time: 187.32997059822083s\n",
      "Loss_dict : {'loss_all': tensor(0.2359, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2562, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [94/100], Step [300/314], Loss: 0.5999 , Use Time: 222.30993700027466s\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.2.weight\n",
      "Epoch [94/100], Average Loss: 1.0280, 1 Epoch Time 231.6482696533203 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch95\n",
      "Loss_dict : {'loss_all': tensor(0.2315, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2598, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [95/100], Step [50/314], Loss: 0.5929 , Use Time: 35.326393604278564s\n",
      "Loss_dict : {'loss_all': tensor(0.2351, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2258, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [95/100], Step [100/314], Loss: 0.5830 , Use Time: 72.36668968200684s\n",
      "Loss_dict : {'loss_all': tensor(0.3590, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3676, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [95/100], Step [150/314], Loss: 0.9018 , Use Time: 111.18690180778503s\n",
      "Loss_dict : {'loss_all': tensor(0.2583, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2744, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [95/100], Step [200/314], Loss: 0.6537 , Use Time: 147.86369466781616s\n",
      "Loss_dict : {'loss_all': tensor(0.2254, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2207, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [95/100], Step [250/314], Loss: 0.5612 , Use Time: 183.49797010421753s\n",
      "Loss_dict : {'loss_all': tensor(0.2452, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2478, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [95/100], Step [300/314], Loss: 0.6144 , Use Time: 218.94474148750305s\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.0.weight\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.1.weight\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.2.weight\n",
      "Epoch [95/100], Average Loss: 1.0268, 1 Epoch Time 228.45324873924255 s\n",
      "Model 95 Already Saved\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch96\n",
      "Loss_dict : {'loss_all': tensor(0.2671, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2803, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [96/100], Step [50/314], Loss: 0.6744 , Use Time: 35.61801218986511s\n",
      "Loss_dict : {'loss_all': tensor(0.3416, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3364, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [96/100], Step [100/314], Loss: 0.8513 , Use Time: 70.81482815742493s\n",
      "Loss_dict : {'loss_all': tensor(0.3092, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3079, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [96/100], Step [150/314], Loss: 0.7723 , Use Time: 106.66153645515442s\n",
      "Loss_dict : {'loss_all': tensor(0.2211, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2519, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [96/100], Step [200/314], Loss: 0.5682 , Use Time: 142.74811720848083s\n",
      "Loss_dict : {'loss_all': tensor(0.2547, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2604, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [96/100], Step [250/314], Loss: 0.6396 , Use Time: 179.2602391242981s\n",
      "Loss_dict : {'loss_all': tensor(0.2941, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2804, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [96/100], Step [300/314], Loss: 0.7283 , Use Time: 215.49812626838684s\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.1.weight\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.2.weight\n",
      "Epoch [96/100], Average Loss: 1.0224, 1 Epoch Time 225.32679224014282 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch97\n",
      "Loss_dict : {'loss_all': tensor(1.0689, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(1.0753, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [97/100], Step [50/314], Loss: 2.6754 , Use Time: 38.822893381118774s\n",
      "Loss_dict : {'loss_all': tensor(0.5581, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.5522, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [97/100], Step [100/314], Loss: 1.3923 , Use Time: 75.91327095031738s\n",
      "Loss_dict : {'loss_all': tensor(0.3230, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3306, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [97/100], Step [150/314], Loss: 0.8113 , Use Time: 111.4229428768158s\n",
      "Loss_dict : {'loss_all': tensor(0.2625, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2818, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [97/100], Step [200/314], Loss: 0.6659 , Use Time: 147.48799538612366s\n",
      "Loss_dict : {'loss_all': tensor(0.4067, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.4238, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [97/100], Step [250/314], Loss: 1.0253 , Use Time: 186.7108473777771s\n",
      "Loss_dict : {'loss_all': tensor(0.2486, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2532, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [97/100], Step [300/314], Loss: 0.6238 , Use Time: 223.54987049102783s\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.1.weight\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.2.weight\n",
      "Epoch [97/100], Average Loss: 1.0247, 1 Epoch Time 233.27442574501038 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch98\n",
      "Loss_dict : {'loss_all': tensor(0.5934, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.5925, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [98/100], Step [50/314], Loss: 1.4832 , Use Time: 36.358205795288086s\n",
      "Loss_dict : {'loss_all': tensor(0.3243, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3164, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [98/100], Step [100/314], Loss: 0.8069 , Use Time: 78.23782992362976s\n",
      "Loss_dict : {'loss_all': tensor(0.2066, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2073, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [98/100], Step [150/314], Loss: 0.5169 , Use Time: 123.25366067886353s\n",
      "Loss_dict : {'loss_all': tensor(1.1060, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(1.1030, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [98/100], Step [200/314], Loss: 2.7635 , Use Time: 173.03228330612183s\n",
      "Loss_dict : {'loss_all': tensor(0.3017, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3227, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [98/100], Step [250/314], Loss: 0.7648 , Use Time: 217.05810284614563s\n",
      "Loss_dict : {'loss_all': tensor(0.2505, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2342, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [98/100], Step [300/314], Loss: 0.6182 , Use Time: 264.60130286216736s\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.2.weight\n",
      "Epoch [98/100], Average Loss: 1.0316, 1 Epoch Time 276.04153633117676 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch99\n",
      "Loss_dict : {'loss_all': tensor(0.2760, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2757, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [99/100], Step [50/314], Loss: 0.6898 , Use Time: 39.96364784240723s\n",
      "Loss_dict : {'loss_all': tensor(0.3979, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.4233, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [99/100], Step [100/314], Loss: 1.0073 , Use Time: 78.95569944381714s\n",
      "Loss_dict : {'loss_all': tensor(0.2993, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3057, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [99/100], Step [150/314], Loss: 0.7514 , Use Time: 121.7926013469696s\n",
      "Loss_dict : {'loss_all': tensor(0.2166, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2242, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [99/100], Step [200/314], Loss: 0.5452 , Use Time: 168.38038849830627s\n",
      "Loss_dict : {'loss_all': tensor(0.3797, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3954, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [99/100], Step [250/314], Loss: 0.9571 , Use Time: 208.64726376533508s\n",
      "Loss_dict : {'loss_all': tensor(0.7894, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.7921, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [99/100], Step [300/314], Loss: 1.9749 , Use Time: 248.57774376869202s\n",
      "Epoch [99/100], Average Loss: 1.0205, 1 Epoch Time 261.3697292804718 s\n",
      "***********************************************************************\n",
      "***********************************************************************\n",
      "start training epoch100\n",
      "Loss_dict : {'loss_all': tensor(2.4278, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(2.4244, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [100/100], Step [50/314], Loss: 6.0677 , Use Time: 38.24493718147278s\n",
      "Loss_dict : {'loss_all': tensor(0.2239, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2340, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [100/100], Step [100/314], Loss: 0.5649 , Use Time: 75.79889178276062s\n",
      "Loss_dict : {'loss_all': tensor(0.2872, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2961, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [100/100], Step [150/314], Loss: 0.7226 , Use Time: 112.67015767097473s\n",
      "Loss_dict : {'loss_all': tensor(0.2309, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2353, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [100/100], Step [200/314], Loss: 0.5794 , Use Time: 149.09715366363525s\n",
      "Loss_dict : {'loss_all': tensor(0.2715, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.2459, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [100/100], Step [250/314], Loss: 0.6660 , Use Time: 185.8267321586609s\n",
      "Loss_dict : {'loss_all': tensor(0.2936, device='cuda:0', grad_fn=<AddBackward0>), 'loss_crnet': tensor(0.3047, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "Epoch [100/100], Step [300/314], Loss: 0.7395 , Use Time: 221.8596031665802s\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.1.weight\n",
      "Step314Warning: Gradient vanishing detected in layer crnet.mce.getf1.2.weight\n",
      "Epoch [100/100], Average Loss: 1.0308, 1 Epoch Time 231.19023489952087 s\n",
      "Model 100 Already Saved\n",
      "***********************************************************************\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df34a9a-6a50-483f-9d37-002ee0f63843",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
